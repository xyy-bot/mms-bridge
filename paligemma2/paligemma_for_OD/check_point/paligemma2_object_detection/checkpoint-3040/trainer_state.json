{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 32.0,
  "eval_steps": 500,
  "global_step": 3040,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 6.3839874267578125,
      "learning_rate": 1.968400263331139e-05,
      "loss": 5.6714,
      "step": 50
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 4.983027458190918,
      "learning_rate": 1.935483870967742e-05,
      "loss": 3.6084,
      "step": 100
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 9.755175590515137,
      "learning_rate": 1.902567478604345e-05,
      "loss": 3.3101,
      "step": 150
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 8.547017097473145,
      "learning_rate": 1.869651086240948e-05,
      "loss": 3.1898,
      "step": 200
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 17.016746520996094,
      "learning_rate": 1.836734693877551e-05,
      "loss": 3.0344,
      "step": 250
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 9.354312896728516,
      "learning_rate": 1.803818301514154e-05,
      "loss": 2.9279,
      "step": 300
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 18.159908294677734,
      "learning_rate": 1.7709019091507573e-05,
      "loss": 2.7859,
      "step": 350
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 15.038930892944336,
      "learning_rate": 1.7379855167873602e-05,
      "loss": 2.6,
      "step": 400
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 18.87519645690918,
      "learning_rate": 1.705069124423963e-05,
      "loss": 2.4429,
      "step": 450
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 14.754435539245605,
      "learning_rate": 1.6721527320605663e-05,
      "loss": 2.3817,
      "step": 500
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 27.696491241455078,
      "learning_rate": 1.6392363396971692e-05,
      "loss": 2.2185,
      "step": 550
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 13.566070556640625,
      "learning_rate": 1.606319947333772e-05,
      "loss": 1.9834,
      "step": 600
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 24.780576705932617,
      "learning_rate": 1.5734035549703754e-05,
      "loss": 1.936,
      "step": 650
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 16.199857711791992,
      "learning_rate": 1.5404871626069783e-05,
      "loss": 1.8148,
      "step": 700
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 20.178943634033203,
      "learning_rate": 1.5075707702435813e-05,
      "loss": 1.7836,
      "step": 750
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 17.510047912597656,
      "learning_rate": 1.4746543778801846e-05,
      "loss": 1.5757,
      "step": 800
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 32.86079406738281,
      "learning_rate": 1.4417379855167875e-05,
      "loss": 1.597,
      "step": 850
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 12.704927444458008,
      "learning_rate": 1.4088215931533904e-05,
      "loss": 1.3448,
      "step": 900
    },
    {
      "epoch": 10.0,
      "grad_norm": 17.202425003051758,
      "learning_rate": 1.3759052007899936e-05,
      "loss": 1.4045,
      "step": 950
    },
    {
      "epoch": 10.526315789473685,
      "grad_norm": 21.663597106933594,
      "learning_rate": 1.3429888084265965e-05,
      "loss": 1.1649,
      "step": 1000
    },
    {
      "epoch": 11.052631578947368,
      "grad_norm": 13.629059791564941,
      "learning_rate": 1.3100724160631996e-05,
      "loss": 1.1807,
      "step": 1050
    },
    {
      "epoch": 11.578947368421053,
      "grad_norm": 26.420970916748047,
      "learning_rate": 1.2771560236998027e-05,
      "loss": 1.03,
      "step": 1100
    },
    {
      "epoch": 12.105263157894736,
      "grad_norm": 27.324838638305664,
      "learning_rate": 1.2442396313364056e-05,
      "loss": 0.9789,
      "step": 1150
    },
    {
      "epoch": 12.631578947368421,
      "grad_norm": 25.412731170654297,
      "learning_rate": 1.2113232389730088e-05,
      "loss": 0.8488,
      "step": 1200
    },
    {
      "epoch": 13.157894736842104,
      "grad_norm": 23.795459747314453,
      "learning_rate": 1.1784068466096117e-05,
      "loss": 0.9661,
      "step": 1250
    },
    {
      "epoch": 13.68421052631579,
      "grad_norm": 30.233049392700195,
      "learning_rate": 1.1454904542462146e-05,
      "loss": 0.7009,
      "step": 1300
    },
    {
      "epoch": 14.210526315789474,
      "grad_norm": 28.533954620361328,
      "learning_rate": 1.1125740618828179e-05,
      "loss": 0.803,
      "step": 1350
    },
    {
      "epoch": 14.736842105263158,
      "grad_norm": 28.423715591430664,
      "learning_rate": 1.0796576695194208e-05,
      "loss": 0.6419,
      "step": 1400
    },
    {
      "epoch": 15.263157894736842,
      "grad_norm": 29.365764617919922,
      "learning_rate": 1.0467412771560237e-05,
      "loss": 0.5888,
      "step": 1450
    },
    {
      "epoch": 15.789473684210526,
      "grad_norm": 11.883700370788574,
      "learning_rate": 1.0138248847926269e-05,
      "loss": 0.5904,
      "step": 1500
    },
    {
      "epoch": 16.31578947368421,
      "grad_norm": 10.881093978881836,
      "learning_rate": 9.809084924292298e-06,
      "loss": 0.5195,
      "step": 1550
    },
    {
      "epoch": 16.842105263157894,
      "grad_norm": 25.098812103271484,
      "learning_rate": 9.479921000658329e-06,
      "loss": 0.4698,
      "step": 1600
    },
    {
      "epoch": 17.36842105263158,
      "grad_norm": 12.0714693069458,
      "learning_rate": 9.15075707702436e-06,
      "loss": 0.4153,
      "step": 1650
    },
    {
      "epoch": 17.894736842105264,
      "grad_norm": 11.74008846282959,
      "learning_rate": 8.821593153390389e-06,
      "loss": 0.4545,
      "step": 1700
    },
    {
      "epoch": 18.42105263157895,
      "grad_norm": 16.674972534179688,
      "learning_rate": 8.49242922975642e-06,
      "loss": 0.3401,
      "step": 1750
    },
    {
      "epoch": 18.94736842105263,
      "grad_norm": 29.124343872070312,
      "learning_rate": 8.16326530612245e-06,
      "loss": 0.3876,
      "step": 1800
    },
    {
      "epoch": 19.473684210526315,
      "grad_norm": 14.934453010559082,
      "learning_rate": 7.83410138248848e-06,
      "loss": 0.287,
      "step": 1850
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.6100387573242188,
      "learning_rate": 7.50493745885451e-06,
      "loss": 0.2899,
      "step": 1900
    },
    {
      "epoch": 20.526315789473685,
      "grad_norm": 24.860057830810547,
      "learning_rate": 7.1757735352205405e-06,
      "loss": 0.2574,
      "step": 1950
    },
    {
      "epoch": 21.05263157894737,
      "grad_norm": 21.312578201293945,
      "learning_rate": 6.846609611586571e-06,
      "loss": 0.2739,
      "step": 2000
    },
    {
      "epoch": 21.57894736842105,
      "grad_norm": 12.945968627929688,
      "learning_rate": 6.5174456879526e-06,
      "loss": 0.1941,
      "step": 2050
    },
    {
      "epoch": 22.105263157894736,
      "grad_norm": 30.903806686401367,
      "learning_rate": 6.188281764318631e-06,
      "loss": 0.2647,
      "step": 2100
    },
    {
      "epoch": 22.63157894736842,
      "grad_norm": 24.92672348022461,
      "learning_rate": 5.859117840684662e-06,
      "loss": 0.2006,
      "step": 2150
    },
    {
      "epoch": 23.157894736842106,
      "grad_norm": 10.67099380493164,
      "learning_rate": 5.529953917050692e-06,
      "loss": 0.1688,
      "step": 2200
    },
    {
      "epoch": 23.68421052631579,
      "grad_norm": 27.092418670654297,
      "learning_rate": 5.200789993416721e-06,
      "loss": 0.1884,
      "step": 2250
    },
    {
      "epoch": 24.210526315789473,
      "grad_norm": 1.2513859272003174,
      "learning_rate": 4.871626069782752e-06,
      "loss": 0.1758,
      "step": 2300
    },
    {
      "epoch": 24.736842105263158,
      "grad_norm": 15.504911422729492,
      "learning_rate": 4.542462146148782e-06,
      "loss": 0.1672,
      "step": 2350
    },
    {
      "epoch": 25.263157894736842,
      "grad_norm": 39.782623291015625,
      "learning_rate": 4.213298222514813e-06,
      "loss": 0.1864,
      "step": 2400
    },
    {
      "epoch": 25.789473684210527,
      "grad_norm": 22.000776290893555,
      "learning_rate": 3.884134298880843e-06,
      "loss": 0.1491,
      "step": 2450
    },
    {
      "epoch": 26.31578947368421,
      "grad_norm": 24.113149642944336,
      "learning_rate": 3.5549703752468733e-06,
      "loss": 0.149,
      "step": 2500
    },
    {
      "epoch": 26.842105263157894,
      "grad_norm": 32.599796295166016,
      "learning_rate": 3.225806451612903e-06,
      "loss": 0.132,
      "step": 2550
    },
    {
      "epoch": 27.36842105263158,
      "grad_norm": 23.280624389648438,
      "learning_rate": 2.896642527978934e-06,
      "loss": 0.1423,
      "step": 2600
    },
    {
      "epoch": 27.894736842105264,
      "grad_norm": 10.793323516845703,
      "learning_rate": 2.5674786043449638e-06,
      "loss": 0.1286,
      "step": 2650
    },
    {
      "epoch": 28.42105263157895,
      "grad_norm": 9.007765769958496,
      "learning_rate": 2.238314680710994e-06,
      "loss": 0.1308,
      "step": 2700
    },
    {
      "epoch": 28.94736842105263,
      "grad_norm": 1.5445353984832764,
      "learning_rate": 1.9091507570770244e-06,
      "loss": 0.1317,
      "step": 2750
    },
    {
      "epoch": 29.473684210526315,
      "grad_norm": 6.761136054992676,
      "learning_rate": 1.5799868334430549e-06,
      "loss": 0.1313,
      "step": 2800
    },
    {
      "epoch": 30.0,
      "grad_norm": 35.53292465209961,
      "learning_rate": 1.2508229098090852e-06,
      "loss": 0.1107,
      "step": 2850
    },
    {
      "epoch": 30.526315789473685,
      "grad_norm": 21.712610244750977,
      "learning_rate": 9.216589861751154e-07,
      "loss": 0.0947,
      "step": 2900
    },
    {
      "epoch": 31.05263157894737,
      "grad_norm": 2.1045358180999756,
      "learning_rate": 5.924950625411456e-07,
      "loss": 0.1233,
      "step": 2950
    },
    {
      "epoch": 31.57894736842105,
      "grad_norm": 21.419248580932617,
      "learning_rate": 2.633311389071758e-07,
      "loss": 0.1453,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3040,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 32,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5952423635132416e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
