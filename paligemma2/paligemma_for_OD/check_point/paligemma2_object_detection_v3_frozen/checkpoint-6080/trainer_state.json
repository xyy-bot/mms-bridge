{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 64.0,
  "eval_steps": 500,
  "global_step": 6080,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 6.873905181884766,
      "learning_rate": 1.9842053307008887e-05,
      "loss": 5.6679,
      "step": 50
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 5.3289265632629395,
      "learning_rate": 1.9677525501809807e-05,
      "loss": 3.598,
      "step": 100
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 10.13400650024414,
      "learning_rate": 1.951299769661073e-05,
      "loss": 3.2982,
      "step": 150
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 8.66196060180664,
      "learning_rate": 1.934846989141165e-05,
      "loss": 3.1751,
      "step": 200
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 17.217071533203125,
      "learning_rate": 1.918394208621257e-05,
      "loss": 3.0077,
      "step": 250
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 9.645879745483398,
      "learning_rate": 1.901941428101349e-05,
      "loss": 2.8922,
      "step": 300
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 18.762832641601562,
      "learning_rate": 1.8854886475814412e-05,
      "loss": 2.7515,
      "step": 350
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 15.99041748046875,
      "learning_rate": 1.8690358670615336e-05,
      "loss": 2.5525,
      "step": 400
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 18.460460662841797,
      "learning_rate": 1.8525830865416256e-05,
      "loss": 2.3966,
      "step": 450
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 15.13276195526123,
      "learning_rate": 1.8361303060217176e-05,
      "loss": 2.3192,
      "step": 500
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 29.180490493774414,
      "learning_rate": 1.81967752550181e-05,
      "loss": 2.1774,
      "step": 550
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 13.208120346069336,
      "learning_rate": 1.803224744981902e-05,
      "loss": 1.9255,
      "step": 600
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 26.255115509033203,
      "learning_rate": 1.7867719644619944e-05,
      "loss": 1.8646,
      "step": 650
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 17.17641258239746,
      "learning_rate": 1.7703191839420864e-05,
      "loss": 1.7434,
      "step": 700
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 19.67397689819336,
      "learning_rate": 1.7538664034221785e-05,
      "loss": 1.717,
      "step": 750
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 17.888538360595703,
      "learning_rate": 1.737413622902271e-05,
      "loss": 1.4947,
      "step": 800
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 30.738008499145508,
      "learning_rate": 1.720960842382363e-05,
      "loss": 1.5071,
      "step": 850
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 11.465002059936523,
      "learning_rate": 1.704508061862455e-05,
      "loss": 1.2488,
      "step": 900
    },
    {
      "epoch": 10.0,
      "grad_norm": 17.50179100036621,
      "learning_rate": 1.688055281342547e-05,
      "loss": 1.2943,
      "step": 950
    },
    {
      "epoch": 10.526315789473685,
      "grad_norm": 22.523393630981445,
      "learning_rate": 1.671602500822639e-05,
      "loss": 1.0633,
      "step": 1000
    },
    {
      "epoch": 11.052631578947368,
      "grad_norm": 12.055278778076172,
      "learning_rate": 1.6551497203027313e-05,
      "loss": 1.0687,
      "step": 1050
    },
    {
      "epoch": 11.578947368421053,
      "grad_norm": 29.46516227722168,
      "learning_rate": 1.6386969397828234e-05,
      "loss": 0.8851,
      "step": 1100
    },
    {
      "epoch": 12.105263157894736,
      "grad_norm": 27.16973304748535,
      "learning_rate": 1.6222441592629157e-05,
      "loss": 0.8734,
      "step": 1150
    },
    {
      "epoch": 12.631578947368421,
      "grad_norm": 24.077272415161133,
      "learning_rate": 1.6057913787430078e-05,
      "loss": 0.7218,
      "step": 1200
    },
    {
      "epoch": 13.157894736842104,
      "grad_norm": 24.99447250366211,
      "learning_rate": 1.5893385982230998e-05,
      "loss": 0.8471,
      "step": 1250
    },
    {
      "epoch": 13.68421052631579,
      "grad_norm": 30.423479080200195,
      "learning_rate": 1.5728858177031922e-05,
      "loss": 0.5718,
      "step": 1300
    },
    {
      "epoch": 14.210526315789474,
      "grad_norm": 32.444061279296875,
      "learning_rate": 1.5564330371832842e-05,
      "loss": 0.6773,
      "step": 1350
    },
    {
      "epoch": 14.736842105263158,
      "grad_norm": 38.103126525878906,
      "learning_rate": 1.5399802566633762e-05,
      "loss": 0.5193,
      "step": 1400
    },
    {
      "epoch": 15.263157894736842,
      "grad_norm": 31.911588668823242,
      "learning_rate": 1.5235274761434684e-05,
      "loss": 0.4873,
      "step": 1450
    },
    {
      "epoch": 15.789473684210526,
      "grad_norm": 7.957418918609619,
      "learning_rate": 1.5070746956235605e-05,
      "loss": 0.461,
      "step": 1500
    },
    {
      "epoch": 16.31578947368421,
      "grad_norm": 9.979344367980957,
      "learning_rate": 1.4906219151036527e-05,
      "loss": 0.427,
      "step": 1550
    },
    {
      "epoch": 16.842105263157894,
      "grad_norm": 23.727981567382812,
      "learning_rate": 1.4741691345837447e-05,
      "loss": 0.3547,
      "step": 1600
    },
    {
      "epoch": 17.36842105263158,
      "grad_norm": 5.103805065155029,
      "learning_rate": 1.4577163540638367e-05,
      "loss": 0.3131,
      "step": 1650
    },
    {
      "epoch": 17.894736842105264,
      "grad_norm": 6.8281683921813965,
      "learning_rate": 1.4412635735439291e-05,
      "loss": 0.3599,
      "step": 1700
    },
    {
      "epoch": 18.42105263157895,
      "grad_norm": 9.648490905761719,
      "learning_rate": 1.4248107930240212e-05,
      "loss": 0.2383,
      "step": 1750
    },
    {
      "epoch": 18.94736842105263,
      "grad_norm": 26.547332763671875,
      "learning_rate": 1.4083580125041134e-05,
      "loss": 0.2984,
      "step": 1800
    },
    {
      "epoch": 19.473684210526315,
      "grad_norm": 9.302014350891113,
      "learning_rate": 1.3919052319842054e-05,
      "loss": 0.209,
      "step": 1850
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.0794625282287598,
      "learning_rate": 1.3754524514642976e-05,
      "loss": 0.2055,
      "step": 1900
    },
    {
      "epoch": 20.526315789473685,
      "grad_norm": 13.855460166931152,
      "learning_rate": 1.3589996709443898e-05,
      "loss": 0.2105,
      "step": 1950
    },
    {
      "epoch": 21.05263157894737,
      "grad_norm": 16.61695671081543,
      "learning_rate": 1.3425468904244818e-05,
      "loss": 0.2138,
      "step": 2000
    },
    {
      "epoch": 21.57894736842105,
      "grad_norm": 7.590754508972168,
      "learning_rate": 1.3260941099045739e-05,
      "loss": 0.128,
      "step": 2050
    },
    {
      "epoch": 22.105263157894736,
      "grad_norm": 38.07894515991211,
      "learning_rate": 1.3096413293846662e-05,
      "loss": 0.2406,
      "step": 2100
    },
    {
      "epoch": 22.63157894736842,
      "grad_norm": 19.159948348999023,
      "learning_rate": 1.2931885488647583e-05,
      "loss": 0.1423,
      "step": 2150
    },
    {
      "epoch": 23.157894736842106,
      "grad_norm": 5.111379623413086,
      "learning_rate": 1.2767357683448505e-05,
      "loss": 0.1416,
      "step": 2200
    },
    {
      "epoch": 23.68421052631579,
      "grad_norm": 21.35247802734375,
      "learning_rate": 1.2602829878249425e-05,
      "loss": 0.1644,
      "step": 2250
    },
    {
      "epoch": 24.210526315789473,
      "grad_norm": 0.36421141028404236,
      "learning_rate": 1.2438302073050345e-05,
      "loss": 0.138,
      "step": 2300
    },
    {
      "epoch": 24.736842105263158,
      "grad_norm": 6.174103260040283,
      "learning_rate": 1.2273774267851269e-05,
      "loss": 0.1368,
      "step": 2350
    },
    {
      "epoch": 25.263157894736842,
      "grad_norm": 40.46882629394531,
      "learning_rate": 1.210924646265219e-05,
      "loss": 0.1701,
      "step": 2400
    },
    {
      "epoch": 25.789473684210527,
      "grad_norm": 16.97718620300293,
      "learning_rate": 1.1944718657453111e-05,
      "loss": 0.1534,
      "step": 2450
    },
    {
      "epoch": 26.31578947368421,
      "grad_norm": 20.08920669555664,
      "learning_rate": 1.1780190852254032e-05,
      "loss": 0.1228,
      "step": 2500
    },
    {
      "epoch": 26.842105263157894,
      "grad_norm": 33.09455108642578,
      "learning_rate": 1.1615663047054952e-05,
      "loss": 0.101,
      "step": 2550
    },
    {
      "epoch": 27.36842105263158,
      "grad_norm": 21.942352294921875,
      "learning_rate": 1.1451135241855876e-05,
      "loss": 0.1332,
      "step": 2600
    },
    {
      "epoch": 27.894736842105264,
      "grad_norm": 11.957265853881836,
      "learning_rate": 1.1286607436656796e-05,
      "loss": 0.1227,
      "step": 2650
    },
    {
      "epoch": 28.42105263157895,
      "grad_norm": 13.325757026672363,
      "learning_rate": 1.1122079631457716e-05,
      "loss": 0.1431,
      "step": 2700
    },
    {
      "epoch": 28.94736842105263,
      "grad_norm": 0.36933261156082153,
      "learning_rate": 1.0957551826258638e-05,
      "loss": 0.1286,
      "step": 2750
    },
    {
      "epoch": 29.473684210526315,
      "grad_norm": 2.053901433944702,
      "learning_rate": 1.0793024021059559e-05,
      "loss": 0.1193,
      "step": 2800
    },
    {
      "epoch": 30.0,
      "grad_norm": 52.78496551513672,
      "learning_rate": 1.0628496215860482e-05,
      "loss": 0.1155,
      "step": 2850
    },
    {
      "epoch": 30.526315789473685,
      "grad_norm": 25.21611213684082,
      "learning_rate": 1.0463968410661403e-05,
      "loss": 0.086,
      "step": 2900
    },
    {
      "epoch": 31.05263157894737,
      "grad_norm": 0.6612006425857544,
      "learning_rate": 1.0299440605462323e-05,
      "loss": 0.1424,
      "step": 2950
    },
    {
      "epoch": 31.57894736842105,
      "grad_norm": 25.591184616088867,
      "learning_rate": 1.0134912800263245e-05,
      "loss": 0.1633,
      "step": 3000
    },
    {
      "epoch": 32.10526315789474,
      "grad_norm": 0.2679602801799774,
      "learning_rate": 9.970384995064165e-06,
      "loss": 0.0867,
      "step": 3050
    },
    {
      "epoch": 32.63157894736842,
      "grad_norm": 13.355823516845703,
      "learning_rate": 9.805857189865087e-06,
      "loss": 0.1064,
      "step": 3100
    },
    {
      "epoch": 33.1578947368421,
      "grad_norm": 14.337000846862793,
      "learning_rate": 9.64132938466601e-06,
      "loss": 0.1268,
      "step": 3150
    },
    {
      "epoch": 33.68421052631579,
      "grad_norm": 4.455465793609619,
      "learning_rate": 9.476801579466932e-06,
      "loss": 0.1097,
      "step": 3200
    },
    {
      "epoch": 34.21052631578947,
      "grad_norm": 0.13438907265663147,
      "learning_rate": 9.312273774267852e-06,
      "loss": 0.1191,
      "step": 3250
    },
    {
      "epoch": 34.73684210526316,
      "grad_norm": 20.84114646911621,
      "learning_rate": 9.147745969068774e-06,
      "loss": 0.1203,
      "step": 3300
    },
    {
      "epoch": 35.26315789473684,
      "grad_norm": 0.5902643203735352,
      "learning_rate": 8.983218163869694e-06,
      "loss": 0.101,
      "step": 3350
    },
    {
      "epoch": 35.78947368421053,
      "grad_norm": 0.07035276293754578,
      "learning_rate": 8.818690358670616e-06,
      "loss": 0.0913,
      "step": 3400
    },
    {
      "epoch": 36.31578947368421,
      "grad_norm": 0.17886796593666077,
      "learning_rate": 8.654162553471538e-06,
      "loss": 0.0557,
      "step": 3450
    },
    {
      "epoch": 36.8421052631579,
      "grad_norm": 0.13136503100395203,
      "learning_rate": 8.489634748272459e-06,
      "loss": 0.1013,
      "step": 3500
    },
    {
      "epoch": 37.36842105263158,
      "grad_norm": 17.962345123291016,
      "learning_rate": 8.32510694307338e-06,
      "loss": 0.1125,
      "step": 3550
    },
    {
      "epoch": 37.89473684210526,
      "grad_norm": 0.08882782608270645,
      "learning_rate": 8.160579137874301e-06,
      "loss": 0.0696,
      "step": 3600
    },
    {
      "epoch": 38.421052631578945,
      "grad_norm": 0.11196357011795044,
      "learning_rate": 7.996051332675223e-06,
      "loss": 0.0894,
      "step": 3650
    },
    {
      "epoch": 38.94736842105263,
      "grad_norm": 0.18779753148555756,
      "learning_rate": 7.831523527476143e-06,
      "loss": 0.0668,
      "step": 3700
    },
    {
      "epoch": 39.473684210526315,
      "grad_norm": 1.6096326112747192,
      "learning_rate": 7.666995722277065e-06,
      "loss": 0.1347,
      "step": 3750
    },
    {
      "epoch": 40.0,
      "grad_norm": 16.574844360351562,
      "learning_rate": 7.5024679170779865e-06,
      "loss": 0.1145,
      "step": 3800
    },
    {
      "epoch": 40.526315789473685,
      "grad_norm": 7.762087821960449,
      "learning_rate": 7.3379401118789085e-06,
      "loss": 0.0782,
      "step": 3850
    },
    {
      "epoch": 41.05263157894737,
      "grad_norm": 0.15738001465797424,
      "learning_rate": 7.17341230667983e-06,
      "loss": 0.1057,
      "step": 3900
    },
    {
      "epoch": 41.578947368421055,
      "grad_norm": 0.08096301555633545,
      "learning_rate": 7.008884501480751e-06,
      "loss": 0.0872,
      "step": 3950
    },
    {
      "epoch": 42.10526315789474,
      "grad_norm": 2.6942644119262695,
      "learning_rate": 6.844356696281672e-06,
      "loss": 0.1023,
      "step": 4000
    },
    {
      "epoch": 42.63157894736842,
      "grad_norm": 23.940176010131836,
      "learning_rate": 6.679828891082594e-06,
      "loss": 0.0942,
      "step": 4050
    },
    {
      "epoch": 43.1578947368421,
      "grad_norm": 1.0598360300064087,
      "learning_rate": 6.515301085883515e-06,
      "loss": 0.0918,
      "step": 4100
    },
    {
      "epoch": 43.68421052631579,
      "grad_norm": 31.527591705322266,
      "learning_rate": 6.3507732806844355e-06,
      "loss": 0.0931,
      "step": 4150
    },
    {
      "epoch": 44.21052631578947,
      "grad_norm": 0.04498448967933655,
      "learning_rate": 6.1862454754853576e-06,
      "loss": 0.1129,
      "step": 4200
    },
    {
      "epoch": 44.73684210526316,
      "grad_norm": 19.990745544433594,
      "learning_rate": 6.021717670286279e-06,
      "loss": 0.0928,
      "step": 4250
    },
    {
      "epoch": 45.26315789473684,
      "grad_norm": 8.104178428649902,
      "learning_rate": 5.857189865087201e-06,
      "loss": 0.0808,
      "step": 4300
    },
    {
      "epoch": 45.78947368421053,
      "grad_norm": 9.076375961303711,
      "learning_rate": 5.692662059888121e-06,
      "loss": 0.051,
      "step": 4350
    },
    {
      "epoch": 46.31578947368421,
      "grad_norm": 22.370018005371094,
      "learning_rate": 5.528134254689042e-06,
      "loss": 0.1105,
      "step": 4400
    },
    {
      "epoch": 46.8421052631579,
      "grad_norm": 0.24607627093791962,
      "learning_rate": 5.363606449489964e-06,
      "loss": 0.0802,
      "step": 4450
    },
    {
      "epoch": 47.36842105263158,
      "grad_norm": 23.505725860595703,
      "learning_rate": 5.1990786442908855e-06,
      "loss": 0.0877,
      "step": 4500
    },
    {
      "epoch": 47.89473684210526,
      "grad_norm": 15.501534461975098,
      "learning_rate": 5.0345508390918075e-06,
      "loss": 0.095,
      "step": 4550
    },
    {
      "epoch": 48.421052631578945,
      "grad_norm": 0.09284577518701553,
      "learning_rate": 4.870023033892729e-06,
      "loss": 0.0779,
      "step": 4600
    },
    {
      "epoch": 48.94736842105263,
      "grad_norm": 14.154272079467773,
      "learning_rate": 4.70549522869365e-06,
      "loss": 0.0738,
      "step": 4650
    },
    {
      "epoch": 49.473684210526315,
      "grad_norm": 0.23964689671993256,
      "learning_rate": 4.540967423494571e-06,
      "loss": 0.0786,
      "step": 4700
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.10222459584474564,
      "learning_rate": 4.376439618295492e-06,
      "loss": 0.0669,
      "step": 4750
    },
    {
      "epoch": 50.526315789473685,
      "grad_norm": 24.805221557617188,
      "learning_rate": 4.211911813096413e-06,
      "loss": 0.0841,
      "step": 4800
    },
    {
      "epoch": 51.05263157894737,
      "grad_norm": 3.0956978797912598,
      "learning_rate": 4.0473840078973345e-06,
      "loss": 0.0576,
      "step": 4850
    },
    {
      "epoch": 51.578947368421055,
      "grad_norm": 0.09788822382688522,
      "learning_rate": 3.8828562026982565e-06,
      "loss": 0.1004,
      "step": 4900
    },
    {
      "epoch": 52.10526315789474,
      "grad_norm": 0.04886750876903534,
      "learning_rate": 3.7183283974991773e-06,
      "loss": 0.0904,
      "step": 4950
    },
    {
      "epoch": 52.63157894736842,
      "grad_norm": 0.08083498477935791,
      "learning_rate": 3.553800592300099e-06,
      "loss": 0.076,
      "step": 5000
    },
    {
      "epoch": 53.1578947368421,
      "grad_norm": 3.400775909423828,
      "learning_rate": 3.3892727871010205e-06,
      "loss": 0.0549,
      "step": 5050
    },
    {
      "epoch": 53.68421052631579,
      "grad_norm": 9.162163734436035,
      "learning_rate": 3.2247449819019417e-06,
      "loss": 0.0933,
      "step": 5100
    },
    {
      "epoch": 54.21052631578947,
      "grad_norm": 12.17936897277832,
      "learning_rate": 3.0602171767028633e-06,
      "loss": 0.0597,
      "step": 5150
    },
    {
      "epoch": 54.73684210526316,
      "grad_norm": 0.039597202092409134,
      "learning_rate": 2.8956893715037844e-06,
      "loss": 0.0495,
      "step": 5200
    },
    {
      "epoch": 55.26315789473684,
      "grad_norm": 4.786719799041748,
      "learning_rate": 2.731161566304706e-06,
      "loss": 0.0621,
      "step": 5250
    },
    {
      "epoch": 55.78947368421053,
      "grad_norm": 0.061748091131448746,
      "learning_rate": 2.566633761105627e-06,
      "loss": 0.0909,
      "step": 5300
    },
    {
      "epoch": 56.31578947368421,
      "grad_norm": 0.051333919167518616,
      "learning_rate": 2.4021059559065484e-06,
      "loss": 0.0736,
      "step": 5350
    },
    {
      "epoch": 56.8421052631579,
      "grad_norm": 0.0402100495994091,
      "learning_rate": 2.23757815070747e-06,
      "loss": 0.0595,
      "step": 5400
    },
    {
      "epoch": 57.36842105263158,
      "grad_norm": 0.31730785965919495,
      "learning_rate": 2.073050345508391e-06,
      "loss": 0.0762,
      "step": 5450
    },
    {
      "epoch": 57.89473684210526,
      "grad_norm": 12.197193145751953,
      "learning_rate": 1.9085225403093123e-06,
      "loss": 0.067,
      "step": 5500
    },
    {
      "epoch": 58.421052631578945,
      "grad_norm": 12.356422424316406,
      "learning_rate": 1.7439947351102337e-06,
      "loss": 0.1036,
      "step": 5550
    },
    {
      "epoch": 58.94736842105263,
      "grad_norm": 16.691375732421875,
      "learning_rate": 1.5794669299111551e-06,
      "loss": 0.0602,
      "step": 5600
    },
    {
      "epoch": 59.473684210526315,
      "grad_norm": 0.620679497718811,
      "learning_rate": 1.4149391247120765e-06,
      "loss": 0.0812,
      "step": 5650
    },
    {
      "epoch": 60.0,
      "grad_norm": 7.78098201751709,
      "learning_rate": 1.2504113195129977e-06,
      "loss": 0.0586,
      "step": 5700
    },
    {
      "epoch": 60.526315789473685,
      "grad_norm": 0.05532124638557434,
      "learning_rate": 1.0858835143139193e-06,
      "loss": 0.08,
      "step": 5750
    },
    {
      "epoch": 61.05263157894737,
      "grad_norm": 0.028212260454893112,
      "learning_rate": 9.213557091148404e-07,
      "loss": 0.0761,
      "step": 5800
    },
    {
      "epoch": 61.578947368421055,
      "grad_norm": 0.059099260717630386,
      "learning_rate": 7.568279039157618e-07,
      "loss": 0.0547,
      "step": 5850
    },
    {
      "epoch": 62.10526315789474,
      "grad_norm": 0.030692895874381065,
      "learning_rate": 5.923000987166832e-07,
      "loss": 0.0921,
      "step": 5900
    },
    {
      "epoch": 62.63157894736842,
      "grad_norm": 11.41686725616455,
      "learning_rate": 4.277722935176045e-07,
      "loss": 0.063,
      "step": 5950
    },
    {
      "epoch": 63.1578947368421,
      "grad_norm": 11.39421558380127,
      "learning_rate": 2.6324448831852583e-07,
      "loss": 0.0923,
      "step": 6000
    },
    {
      "epoch": 63.68421052631579,
      "grad_norm": 13.04202651977539,
      "learning_rate": 9.87166831194472e-08,
      "loss": 0.0676,
      "step": 6050
    }
  ],
  "logging_steps": 50,
  "max_steps": 6080,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 64,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.190484727026483e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
