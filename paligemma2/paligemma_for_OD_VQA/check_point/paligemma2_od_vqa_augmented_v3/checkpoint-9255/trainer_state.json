{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 9255,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08103727714748785,
      "grad_norm": 20.87368392944336,
      "learning_rate": 1.9896249864908678e-05,
      "loss": 10.9491,
      "step": 50
    },
    {
      "epoch": 0.1620745542949757,
      "grad_norm": 27.764745712280273,
      "learning_rate": 1.9788176807521885e-05,
      "loss": 4.0804,
      "step": 100
    },
    {
      "epoch": 0.24311183144246354,
      "grad_norm": 30.72478675842285,
      "learning_rate": 1.968010375013509e-05,
      "loss": 1.7796,
      "step": 150
    },
    {
      "epoch": 0.3241491085899514,
      "grad_norm": 10.200011253356934,
      "learning_rate": 1.95720306927483e-05,
      "loss": 1.5625,
      "step": 200
    },
    {
      "epoch": 0.4051863857374392,
      "grad_norm": 17.292463302612305,
      "learning_rate": 1.9463957635361505e-05,
      "loss": 1.2342,
      "step": 250
    },
    {
      "epoch": 0.4862236628849271,
      "grad_norm": 9.753273963928223,
      "learning_rate": 1.9355884577974712e-05,
      "loss": 0.9516,
      "step": 300
    },
    {
      "epoch": 0.5672609400324149,
      "grad_norm": 38.42975616455078,
      "learning_rate": 1.924781152058792e-05,
      "loss": 1.1405,
      "step": 350
    },
    {
      "epoch": 0.6482982171799028,
      "grad_norm": 26.846227645874023,
      "learning_rate": 1.9139738463201126e-05,
      "loss": 1.5854,
      "step": 400
    },
    {
      "epoch": 0.7293354943273906,
      "grad_norm": 3.9712135791778564,
      "learning_rate": 1.9031665405814332e-05,
      "loss": 0.9576,
      "step": 450
    },
    {
      "epoch": 0.8103727714748784,
      "grad_norm": 23.574724197387695,
      "learning_rate": 1.892359234842754e-05,
      "loss": 0.9936,
      "step": 500
    },
    {
      "epoch": 0.8914100486223663,
      "grad_norm": 1.56535804271698,
      "learning_rate": 1.8815519291040746e-05,
      "loss": 1.0204,
      "step": 550
    },
    {
      "epoch": 0.9724473257698542,
      "grad_norm": 13.042433738708496,
      "learning_rate": 1.8707446233653953e-05,
      "loss": 1.2248,
      "step": 600
    },
    {
      "epoch": 1.053484602917342,
      "grad_norm": 6.0308451652526855,
      "learning_rate": 1.859937317626716e-05,
      "loss": 0.9141,
      "step": 650
    },
    {
      "epoch": 1.1345218800648298,
      "grad_norm": 8.037671089172363,
      "learning_rate": 1.8491300118880363e-05,
      "loss": 0.7873,
      "step": 700
    },
    {
      "epoch": 1.2155591572123177,
      "grad_norm": 2.926234722137451,
      "learning_rate": 1.8383227061493573e-05,
      "loss": 0.9965,
      "step": 750
    },
    {
      "epoch": 1.2965964343598055,
      "grad_norm": 2.1781156063079834,
      "learning_rate": 1.827515400410678e-05,
      "loss": 0.7862,
      "step": 800
    },
    {
      "epoch": 1.3776337115072934,
      "grad_norm": 0.5532997846603394,
      "learning_rate": 1.8167080946719983e-05,
      "loss": 0.6489,
      "step": 850
    },
    {
      "epoch": 1.4586709886547813,
      "grad_norm": 14.103527069091797,
      "learning_rate": 1.805900788933319e-05,
      "loss": 1.2277,
      "step": 900
    },
    {
      "epoch": 1.5397082658022692,
      "grad_norm": 5.000462532043457,
      "learning_rate": 1.7950934831946397e-05,
      "loss": 0.8214,
      "step": 950
    },
    {
      "epoch": 1.620745542949757,
      "grad_norm": 0.39316052198410034,
      "learning_rate": 1.7842861774559604e-05,
      "loss": 1.0093,
      "step": 1000
    },
    {
      "epoch": 1.7017828200972447,
      "grad_norm": 0.12262521684169769,
      "learning_rate": 1.773478871717281e-05,
      "loss": 0.992,
      "step": 1050
    },
    {
      "epoch": 1.7828200972447326,
      "grad_norm": 12.9822359085083,
      "learning_rate": 1.7626715659786017e-05,
      "loss": 0.9089,
      "step": 1100
    },
    {
      "epoch": 1.8638573743922204,
      "grad_norm": 12.575008392333984,
      "learning_rate": 1.7518642602399224e-05,
      "loss": 0.6773,
      "step": 1150
    },
    {
      "epoch": 1.9448946515397083,
      "grad_norm": 15.729269981384277,
      "learning_rate": 1.741056954501243e-05,
      "loss": 0.9389,
      "step": 1200
    },
    {
      "epoch": 2.025931928687196,
      "grad_norm": 1.2145836353302002,
      "learning_rate": 1.7302496487625638e-05,
      "loss": 1.0118,
      "step": 1250
    },
    {
      "epoch": 2.106969205834684,
      "grad_norm": 0.05875641852617264,
      "learning_rate": 1.719442343023884e-05,
      "loss": 0.6812,
      "step": 1300
    },
    {
      "epoch": 2.1880064829821717,
      "grad_norm": 11.860849380493164,
      "learning_rate": 1.708635037285205e-05,
      "loss": 0.9073,
      "step": 1350
    },
    {
      "epoch": 2.2690437601296596,
      "grad_norm": 0.24494126439094543,
      "learning_rate": 1.6978277315465258e-05,
      "loss": 1.0636,
      "step": 1400
    },
    {
      "epoch": 2.3500810372771475,
      "grad_norm": 7.280073642730713,
      "learning_rate": 1.687020425807846e-05,
      "loss": 0.7985,
      "step": 1450
    },
    {
      "epoch": 2.4311183144246353,
      "grad_norm": 11.891105651855469,
      "learning_rate": 1.6762131200691668e-05,
      "loss": 0.8377,
      "step": 1500
    },
    {
      "epoch": 2.512155591572123,
      "grad_norm": 24.31134605407715,
      "learning_rate": 1.6654058143304875e-05,
      "loss": 0.7388,
      "step": 1550
    },
    {
      "epoch": 2.593192868719611,
      "grad_norm": 4.252537727355957,
      "learning_rate": 1.6545985085918082e-05,
      "loss": 0.7965,
      "step": 1600
    },
    {
      "epoch": 2.674230145867099,
      "grad_norm": 12.183571815490723,
      "learning_rate": 1.643791202853129e-05,
      "loss": 0.824,
      "step": 1650
    },
    {
      "epoch": 2.755267423014587,
      "grad_norm": 0.30268311500549316,
      "learning_rate": 1.6329838971144495e-05,
      "loss": 0.6058,
      "step": 1700
    },
    {
      "epoch": 2.8363047001620747,
      "grad_norm": 1.546033263206482,
      "learning_rate": 1.6221765913757702e-05,
      "loss": 0.6267,
      "step": 1750
    },
    {
      "epoch": 2.9173419773095626,
      "grad_norm": 0.03677543252706528,
      "learning_rate": 1.611369285637091e-05,
      "loss": 0.7638,
      "step": 1800
    },
    {
      "epoch": 2.99837925445705,
      "grad_norm": 15.12397289276123,
      "learning_rate": 1.6005619798984116e-05,
      "loss": 0.7935,
      "step": 1850
    },
    {
      "epoch": 3.079416531604538,
      "grad_norm": 0.8186268210411072,
      "learning_rate": 1.589754674159732e-05,
      "loss": 0.674,
      "step": 1900
    },
    {
      "epoch": 3.1604538087520258,
      "grad_norm": 15.503986358642578,
      "learning_rate": 1.578947368421053e-05,
      "loss": 0.5974,
      "step": 1950
    },
    {
      "epoch": 3.2414910858995136,
      "grad_norm": 0.07585291564464569,
      "learning_rate": 1.5681400626823736e-05,
      "loss": 0.4384,
      "step": 2000
    },
    {
      "epoch": 3.3225283630470015,
      "grad_norm": 0.06366882473230362,
      "learning_rate": 1.557332756943694e-05,
      "loss": 0.9631,
      "step": 2050
    },
    {
      "epoch": 3.4035656401944894,
      "grad_norm": 12.7767915725708,
      "learning_rate": 1.5465254512050146e-05,
      "loss": 0.6557,
      "step": 2100
    },
    {
      "epoch": 3.4846029173419772,
      "grad_norm": 3.010953664779663,
      "learning_rate": 1.5357181454663353e-05,
      "loss": 0.5642,
      "step": 2150
    },
    {
      "epoch": 3.565640194489465,
      "grad_norm": 0.022410986945033073,
      "learning_rate": 1.524910839727656e-05,
      "loss": 0.9663,
      "step": 2200
    },
    {
      "epoch": 3.646677471636953,
      "grad_norm": 0.3444937467575073,
      "learning_rate": 1.5141035339889767e-05,
      "loss": 0.8234,
      "step": 2250
    },
    {
      "epoch": 3.727714748784441,
      "grad_norm": 10.533573150634766,
      "learning_rate": 1.5032962282502975e-05,
      "loss": 0.564,
      "step": 2300
    },
    {
      "epoch": 3.8087520259319287,
      "grad_norm": 15.98818588256836,
      "learning_rate": 1.4924889225116178e-05,
      "loss": 0.5765,
      "step": 2350
    },
    {
      "epoch": 3.8897893030794166,
      "grad_norm": 0.013930597342550755,
      "learning_rate": 1.4816816167729387e-05,
      "loss": 0.698,
      "step": 2400
    },
    {
      "epoch": 3.9708265802269045,
      "grad_norm": 0.2905803620815277,
      "learning_rate": 1.4708743110342594e-05,
      "loss": 0.7072,
      "step": 2450
    },
    {
      "epoch": 4.051863857374392,
      "grad_norm": 2.6277401447296143,
      "learning_rate": 1.4600670052955799e-05,
      "loss": 0.5258,
      "step": 2500
    },
    {
      "epoch": 4.13290113452188,
      "grad_norm": 15.186760902404785,
      "learning_rate": 1.4492596995569006e-05,
      "loss": 0.3784,
      "step": 2550
    },
    {
      "epoch": 4.213938411669368,
      "grad_norm": 0.30557534098625183,
      "learning_rate": 1.4384523938182214e-05,
      "loss": 0.5771,
      "step": 2600
    },
    {
      "epoch": 4.294975688816856,
      "grad_norm": 0.01273975521326065,
      "learning_rate": 1.4276450880795419e-05,
      "loss": 0.5533,
      "step": 2650
    },
    {
      "epoch": 4.376012965964343,
      "grad_norm": 0.10560527443885803,
      "learning_rate": 1.4168377823408626e-05,
      "loss": 0.7106,
      "step": 2700
    },
    {
      "epoch": 4.457050243111832,
      "grad_norm": 0.008130015805363655,
      "learning_rate": 1.4060304766021833e-05,
      "loss": 0.6216,
      "step": 2750
    },
    {
      "epoch": 4.538087520259319,
      "grad_norm": 13.973538398742676,
      "learning_rate": 1.3952231708635038e-05,
      "loss": 0.4699,
      "step": 2800
    },
    {
      "epoch": 4.6191247974068075,
      "grad_norm": 9.07919692993164,
      "learning_rate": 1.3844158651248245e-05,
      "loss": 0.6384,
      "step": 2850
    },
    {
      "epoch": 4.700162074554295,
      "grad_norm": 0.008372094482183456,
      "learning_rate": 1.3736085593861453e-05,
      "loss": 0.7139,
      "step": 2900
    },
    {
      "epoch": 4.781199351701783,
      "grad_norm": 0.012899219058454037,
      "learning_rate": 1.3628012536474658e-05,
      "loss": 0.5776,
      "step": 2950
    },
    {
      "epoch": 4.862236628849271,
      "grad_norm": 7.908499717712402,
      "learning_rate": 1.3519939479087865e-05,
      "loss": 0.5888,
      "step": 3000
    },
    {
      "epoch": 4.943273905996758,
      "grad_norm": 0.008261920884251595,
      "learning_rate": 1.3411866421701072e-05,
      "loss": 0.6593,
      "step": 3050
    },
    {
      "epoch": 5.024311183144246,
      "grad_norm": 20.234970092773438,
      "learning_rate": 1.3303793364314277e-05,
      "loss": 0.6203,
      "step": 3100
    },
    {
      "epoch": 5.105348460291734,
      "grad_norm": 11.636222839355469,
      "learning_rate": 1.3195720306927484e-05,
      "loss": 0.5567,
      "step": 3150
    },
    {
      "epoch": 5.186385737439222,
      "grad_norm": 2.0275847911834717,
      "learning_rate": 1.3087647249540692e-05,
      "loss": 0.5416,
      "step": 3200
    },
    {
      "epoch": 5.26742301458671,
      "grad_norm": 0.0068822898901999,
      "learning_rate": 1.2979574192153897e-05,
      "loss": 0.3117,
      "step": 3250
    },
    {
      "epoch": 5.348460291734198,
      "grad_norm": 47.20304870605469,
      "learning_rate": 1.2871501134767104e-05,
      "loss": 0.4668,
      "step": 3300
    },
    {
      "epoch": 5.429497568881685,
      "grad_norm": 29.488801956176758,
      "learning_rate": 1.276342807738031e-05,
      "loss": 0.5742,
      "step": 3350
    },
    {
      "epoch": 5.510534846029174,
      "grad_norm": 0.005054150708019733,
      "learning_rate": 1.2655355019993516e-05,
      "loss": 0.5074,
      "step": 3400
    },
    {
      "epoch": 5.591572123176661,
      "grad_norm": 10.366287231445312,
      "learning_rate": 1.2547281962606723e-05,
      "loss": 0.6504,
      "step": 3450
    },
    {
      "epoch": 5.672609400324149,
      "grad_norm": 12.604414939880371,
      "learning_rate": 1.2439208905219931e-05,
      "loss": 0.566,
      "step": 3500
    },
    {
      "epoch": 5.753646677471637,
      "grad_norm": 27.144855499267578,
      "learning_rate": 1.2331135847833136e-05,
      "loss": 0.4845,
      "step": 3550
    },
    {
      "epoch": 5.834683954619125,
      "grad_norm": 0.008751238696277142,
      "learning_rate": 1.2223062790446343e-05,
      "loss": 0.4623,
      "step": 3600
    },
    {
      "epoch": 5.915721231766613,
      "grad_norm": 0.005633518099784851,
      "learning_rate": 1.211498973305955e-05,
      "loss": 0.4291,
      "step": 3650
    },
    {
      "epoch": 5.9967585089141,
      "grad_norm": 0.008056453429162502,
      "learning_rate": 1.2006916675672755e-05,
      "loss": 0.6112,
      "step": 3700
    },
    {
      "epoch": 6.077795786061588,
      "grad_norm": 23.598369598388672,
      "learning_rate": 1.1898843618285962e-05,
      "loss": 0.429,
      "step": 3750
    },
    {
      "epoch": 6.158833063209076,
      "grad_norm": 0.0699266791343689,
      "learning_rate": 1.179077056089917e-05,
      "loss": 0.3036,
      "step": 3800
    },
    {
      "epoch": 6.239870340356564,
      "grad_norm": 0.004453141242265701,
      "learning_rate": 1.1682697503512375e-05,
      "loss": 0.4318,
      "step": 3850
    },
    {
      "epoch": 6.3209076175040515,
      "grad_norm": 0.006733473390340805,
      "learning_rate": 1.1574624446125582e-05,
      "loss": 0.376,
      "step": 3900
    },
    {
      "epoch": 6.40194489465154,
      "grad_norm": 8.283797264099121,
      "learning_rate": 1.1466551388738789e-05,
      "loss": 0.3783,
      "step": 3950
    },
    {
      "epoch": 6.482982171799027,
      "grad_norm": 24.529796600341797,
      "learning_rate": 1.1358478331351994e-05,
      "loss": 0.4231,
      "step": 4000
    },
    {
      "epoch": 6.564019448946516,
      "grad_norm": 6.468812465667725,
      "learning_rate": 1.12504052739652e-05,
      "loss": 0.6587,
      "step": 4050
    },
    {
      "epoch": 6.645056726094003,
      "grad_norm": 0.032771188765764236,
      "learning_rate": 1.114233221657841e-05,
      "loss": 0.4469,
      "step": 4100
    },
    {
      "epoch": 6.726094003241491,
      "grad_norm": 0.014192596077919006,
      "learning_rate": 1.1034259159191614e-05,
      "loss": 0.5161,
      "step": 4150
    },
    {
      "epoch": 6.807131280388979,
      "grad_norm": 0.002396445954218507,
      "learning_rate": 1.0926186101804821e-05,
      "loss": 0.3881,
      "step": 4200
    },
    {
      "epoch": 6.888168557536467,
      "grad_norm": 14.691019058227539,
      "learning_rate": 1.0818113044418028e-05,
      "loss": 0.5043,
      "step": 4250
    },
    {
      "epoch": 6.9692058346839545,
      "grad_norm": 13.938774108886719,
      "learning_rate": 1.0710039987031233e-05,
      "loss": 0.5384,
      "step": 4300
    },
    {
      "epoch": 7.050243111831443,
      "grad_norm": 0.00860859826207161,
      "learning_rate": 1.060196692964444e-05,
      "loss": 0.3721,
      "step": 4350
    },
    {
      "epoch": 7.13128038897893,
      "grad_norm": 0.003379437606781721,
      "learning_rate": 1.0493893872257648e-05,
      "loss": 0.4014,
      "step": 4400
    },
    {
      "epoch": 7.212317666126419,
      "grad_norm": 13.022550582885742,
      "learning_rate": 1.0385820814870853e-05,
      "loss": 0.3153,
      "step": 4450
    },
    {
      "epoch": 7.293354943273906,
      "grad_norm": 0.0036394388880580664,
      "learning_rate": 1.027774775748406e-05,
      "loss": 0.3351,
      "step": 4500
    },
    {
      "epoch": 7.374392220421393,
      "grad_norm": 0.003364487085491419,
      "learning_rate": 1.0169674700097267e-05,
      "loss": 0.573,
      "step": 4550
    },
    {
      "epoch": 7.455429497568882,
      "grad_norm": 9.91411018371582,
      "learning_rate": 1.0061601642710472e-05,
      "loss": 0.2827,
      "step": 4600
    },
    {
      "epoch": 7.536466774716369,
      "grad_norm": 13.25772476196289,
      "learning_rate": 9.95352858532368e-06,
      "loss": 0.3747,
      "step": 4650
    },
    {
      "epoch": 7.6175040518638575,
      "grad_norm": 0.0025185300037264824,
      "learning_rate": 9.845455527936886e-06,
      "loss": 0.3872,
      "step": 4700
    },
    {
      "epoch": 7.698541329011345,
      "grad_norm": 25.78628921508789,
      "learning_rate": 9.737382470550092e-06,
      "loss": 0.5497,
      "step": 4750
    },
    {
      "epoch": 7.779578606158833,
      "grad_norm": 0.00220358744263649,
      "learning_rate": 9.629309413163299e-06,
      "loss": 0.3108,
      "step": 4800
    },
    {
      "epoch": 7.860615883306321,
      "grad_norm": 45.661617279052734,
      "learning_rate": 9.521236355776506e-06,
      "loss": 0.4874,
      "step": 4850
    },
    {
      "epoch": 7.941653160453809,
      "grad_norm": 0.0031294526997953653,
      "learning_rate": 9.413163298389713e-06,
      "loss": 0.4808,
      "step": 4900
    },
    {
      "epoch": 8.022690437601296,
      "grad_norm": 0.019185801967978477,
      "learning_rate": 9.30509024100292e-06,
      "loss": 0.2048,
      "step": 4950
    },
    {
      "epoch": 8.103727714748784,
      "grad_norm": 0.0032259225845336914,
      "learning_rate": 9.197017183616125e-06,
      "loss": 0.2416,
      "step": 5000
    },
    {
      "epoch": 8.184764991896273,
      "grad_norm": 0.003656347980722785,
      "learning_rate": 9.088944126229331e-06,
      "loss": 0.2833,
      "step": 5050
    },
    {
      "epoch": 8.26580226904376,
      "grad_norm": 17.59589385986328,
      "learning_rate": 8.980871068842538e-06,
      "loss": 0.314,
      "step": 5100
    },
    {
      "epoch": 8.346839546191248,
      "grad_norm": 0.015912402421236038,
      "learning_rate": 8.872798011455745e-06,
      "loss": 0.3172,
      "step": 5150
    },
    {
      "epoch": 8.427876823338735,
      "grad_norm": 37.18238830566406,
      "learning_rate": 8.764724954068952e-06,
      "loss": 0.4194,
      "step": 5200
    },
    {
      "epoch": 8.508914100486223,
      "grad_norm": 0.012158224359154701,
      "learning_rate": 8.656651896682158e-06,
      "loss": 0.3488,
      "step": 5250
    },
    {
      "epoch": 8.589951377633712,
      "grad_norm": 3.403982639312744,
      "learning_rate": 8.548578839295364e-06,
      "loss": 0.2681,
      "step": 5300
    },
    {
      "epoch": 8.6709886547812,
      "grad_norm": 0.039684951305389404,
      "learning_rate": 8.44050578190857e-06,
      "loss": 0.3208,
      "step": 5350
    },
    {
      "epoch": 8.752025931928687,
      "grad_norm": 0.0021238529589027166,
      "learning_rate": 8.332432724521777e-06,
      "loss": 0.3706,
      "step": 5400
    },
    {
      "epoch": 8.833063209076174,
      "grad_norm": 0.003615122754126787,
      "learning_rate": 8.224359667134984e-06,
      "loss": 0.3731,
      "step": 5450
    },
    {
      "epoch": 8.914100486223663,
      "grad_norm": 0.007722103036940098,
      "learning_rate": 8.11628660974819e-06,
      "loss": 0.2311,
      "step": 5500
    },
    {
      "epoch": 8.995137763371151,
      "grad_norm": 0.0021755106281489134,
      "learning_rate": 8.008213552361397e-06,
      "loss": 0.4488,
      "step": 5550
    },
    {
      "epoch": 9.076175040518638,
      "grad_norm": 0.0029689373914152384,
      "learning_rate": 7.900140494974603e-06,
      "loss": 0.1798,
      "step": 5600
    },
    {
      "epoch": 9.157212317666126,
      "grad_norm": 0.004450540523976088,
      "learning_rate": 7.792067437587811e-06,
      "loss": 0.3102,
      "step": 5650
    },
    {
      "epoch": 9.238249594813615,
      "grad_norm": 12.300225257873535,
      "learning_rate": 7.683994380201016e-06,
      "loss": 0.2719,
      "step": 5700
    },
    {
      "epoch": 9.319286871961102,
      "grad_norm": 0.037029922008514404,
      "learning_rate": 7.575921322814223e-06,
      "loss": 0.3129,
      "step": 5750
    },
    {
      "epoch": 9.40032414910859,
      "grad_norm": 0.021054266020655632,
      "learning_rate": 7.46784826542743e-06,
      "loss": 0.2696,
      "step": 5800
    },
    {
      "epoch": 9.481361426256077,
      "grad_norm": 0.004048818256705999,
      "learning_rate": 7.359775208040636e-06,
      "loss": 0.3343,
      "step": 5850
    },
    {
      "epoch": 9.562398703403566,
      "grad_norm": 0.005706738214939833,
      "learning_rate": 7.2517021506538424e-06,
      "loss": 0.301,
      "step": 5900
    },
    {
      "epoch": 9.643435980551054,
      "grad_norm": 0.03410261124372482,
      "learning_rate": 7.143629093267049e-06,
      "loss": 0.2599,
      "step": 5950
    },
    {
      "epoch": 9.724473257698541,
      "grad_norm": 0.006151157896965742,
      "learning_rate": 7.035556035880255e-06,
      "loss": 0.2034,
      "step": 6000
    },
    {
      "epoch": 9.805510534846029,
      "grad_norm": 7.298527240753174,
      "learning_rate": 6.927482978493462e-06,
      "loss": 0.1616,
      "step": 6050
    },
    {
      "epoch": 9.886547811993516,
      "grad_norm": 8.598465919494629,
      "learning_rate": 6.819409921106669e-06,
      "loss": 0.2994,
      "step": 6100
    },
    {
      "epoch": 9.967585089141005,
      "grad_norm": 0.01464955322444439,
      "learning_rate": 6.711336863719875e-06,
      "loss": 0.2681,
      "step": 6150
    },
    {
      "epoch": 10.048622366288493,
      "grad_norm": 15.661499977111816,
      "learning_rate": 6.6032638063330815e-06,
      "loss": 0.2642,
      "step": 6200
    },
    {
      "epoch": 10.12965964343598,
      "grad_norm": 0.003758026985451579,
      "learning_rate": 6.495190748946288e-06,
      "loss": 0.3025,
      "step": 6250
    },
    {
      "epoch": 10.210696920583468,
      "grad_norm": 0.0031766158062964678,
      "learning_rate": 6.387117691559494e-06,
      "loss": 0.1742,
      "step": 6300
    },
    {
      "epoch": 10.291734197730957,
      "grad_norm": 0.006273183040320873,
      "learning_rate": 6.279044634172701e-06,
      "loss": 0.2676,
      "step": 6350
    },
    {
      "epoch": 10.372771474878444,
      "grad_norm": 0.0017434157198294997,
      "learning_rate": 6.170971576785908e-06,
      "loss": 0.1308,
      "step": 6400
    },
    {
      "epoch": 10.453808752025932,
      "grad_norm": 0.003005944425240159,
      "learning_rate": 6.062898519399114e-06,
      "loss": 0.214,
      "step": 6450
    },
    {
      "epoch": 10.53484602917342,
      "grad_norm": 27.9110164642334,
      "learning_rate": 5.954825462012321e-06,
      "loss": 0.2525,
      "step": 6500
    },
    {
      "epoch": 10.615883306320908,
      "grad_norm": 0.002308476949110627,
      "learning_rate": 5.846752404625527e-06,
      "loss": 0.1251,
      "step": 6550
    },
    {
      "epoch": 10.696920583468396,
      "grad_norm": 6.802023887634277,
      "learning_rate": 5.738679347238734e-06,
      "loss": 0.1553,
      "step": 6600
    },
    {
      "epoch": 10.777957860615883,
      "grad_norm": 18.00678825378418,
      "learning_rate": 5.630606289851941e-06,
      "loss": 0.1883,
      "step": 6650
    },
    {
      "epoch": 10.85899513776337,
      "grad_norm": 0.25745072960853577,
      "learning_rate": 5.522533232465147e-06,
      "loss": 0.3125,
      "step": 6700
    },
    {
      "epoch": 10.94003241491086,
      "grad_norm": 6.524657726287842,
      "learning_rate": 5.4144601750783536e-06,
      "loss": 0.2649,
      "step": 6750
    },
    {
      "epoch": 11.021069692058347,
      "grad_norm": 0.004489323124289513,
      "learning_rate": 5.30638711769156e-06,
      "loss": 0.1708,
      "step": 6800
    },
    {
      "epoch": 11.102106969205835,
      "grad_norm": 0.0069734263233840466,
      "learning_rate": 5.198314060304766e-06,
      "loss": 0.1627,
      "step": 6850
    },
    {
      "epoch": 11.183144246353322,
      "grad_norm": 0.012555726803839207,
      "learning_rate": 5.090241002917973e-06,
      "loss": 0.1867,
      "step": 6900
    },
    {
      "epoch": 11.26418152350081,
      "grad_norm": 25.81973648071289,
      "learning_rate": 4.982167945531179e-06,
      "loss": 0.1697,
      "step": 6950
    },
    {
      "epoch": 11.345218800648299,
      "grad_norm": 0.011556464247405529,
      "learning_rate": 4.874094888144386e-06,
      "loss": 0.1299,
      "step": 7000
    },
    {
      "epoch": 11.426256077795786,
      "grad_norm": 0.00929015502333641,
      "learning_rate": 4.766021830757593e-06,
      "loss": 0.223,
      "step": 7050
    },
    {
      "epoch": 11.507293354943274,
      "grad_norm": 0.012414015829563141,
      "learning_rate": 4.657948773370799e-06,
      "loss": 0.125,
      "step": 7100
    },
    {
      "epoch": 11.588330632090761,
      "grad_norm": 0.003699025372043252,
      "learning_rate": 4.549875715984005e-06,
      "loss": 0.1101,
      "step": 7150
    },
    {
      "epoch": 11.66936790923825,
      "grad_norm": 0.0026218697894364595,
      "learning_rate": 4.441802658597212e-06,
      "loss": 0.1607,
      "step": 7200
    },
    {
      "epoch": 11.750405186385738,
      "grad_norm": 22.58397102355957,
      "learning_rate": 4.333729601210419e-06,
      "loss": 0.2316,
      "step": 7250
    },
    {
      "epoch": 11.831442463533225,
      "grad_norm": 19.537946701049805,
      "learning_rate": 4.225656543823625e-06,
      "loss": 0.2209,
      "step": 7300
    },
    {
      "epoch": 11.912479740680713,
      "grad_norm": 0.0015222843503579497,
      "learning_rate": 4.117583486436832e-06,
      "loss": 0.2273,
      "step": 7350
    },
    {
      "epoch": 11.993517017828202,
      "grad_norm": 9.539031982421875,
      "learning_rate": 4.009510429050038e-06,
      "loss": 0.115,
      "step": 7400
    },
    {
      "epoch": 12.07455429497569,
      "grad_norm": 0.0025121821090579033,
      "learning_rate": 3.901437371663245e-06,
      "loss": 0.135,
      "step": 7450
    },
    {
      "epoch": 12.155591572123177,
      "grad_norm": 0.0019659423269331455,
      "learning_rate": 3.7933643142764515e-06,
      "loss": 0.1285,
      "step": 7500
    },
    {
      "epoch": 12.236628849270664,
      "grad_norm": 0.007907649502158165,
      "learning_rate": 3.6852912568896575e-06,
      "loss": 0.1159,
      "step": 7550
    },
    {
      "epoch": 12.317666126418152,
      "grad_norm": 0.007861174643039703,
      "learning_rate": 3.5772181995028643e-06,
      "loss": 0.1254,
      "step": 7600
    },
    {
      "epoch": 12.39870340356564,
      "grad_norm": 13.347341537475586,
      "learning_rate": 3.469145142116071e-06,
      "loss": 0.1386,
      "step": 7650
    },
    {
      "epoch": 12.479740680713128,
      "grad_norm": 0.006381620187312365,
      "learning_rate": 3.361072084729277e-06,
      "loss": 0.1702,
      "step": 7700
    },
    {
      "epoch": 12.560777957860616,
      "grad_norm": 0.00191471166908741,
      "learning_rate": 3.2529990273424838e-06,
      "loss": 0.1107,
      "step": 7750
    },
    {
      "epoch": 12.641815235008103,
      "grad_norm": 0.0026367786340415478,
      "learning_rate": 3.1449259699556906e-06,
      "loss": 0.1424,
      "step": 7800
    },
    {
      "epoch": 12.722852512155592,
      "grad_norm": 0.0031014038249850273,
      "learning_rate": 3.0368529125688965e-06,
      "loss": 0.0896,
      "step": 7850
    },
    {
      "epoch": 12.80388978930308,
      "grad_norm": 16.047760009765625,
      "learning_rate": 2.9287798551821033e-06,
      "loss": 0.0913,
      "step": 7900
    },
    {
      "epoch": 12.884927066450567,
      "grad_norm": 0.0032107739243656397,
      "learning_rate": 2.82070679779531e-06,
      "loss": 0.1531,
      "step": 7950
    },
    {
      "epoch": 12.965964343598054,
      "grad_norm": 0.0035867749247699976,
      "learning_rate": 2.7126337404085164e-06,
      "loss": 0.178,
      "step": 8000
    },
    {
      "epoch": 13.047001620745544,
      "grad_norm": 0.003974131774157286,
      "learning_rate": 2.604560683021723e-06,
      "loss": 0.0836,
      "step": 8050
    },
    {
      "epoch": 13.128038897893031,
      "grad_norm": 0.0026969709433615208,
      "learning_rate": 2.496487625634929e-06,
      "loss": 0.1069,
      "step": 8100
    },
    {
      "epoch": 13.209076175040519,
      "grad_norm": 13.293478012084961,
      "learning_rate": 2.388414568248136e-06,
      "loss": 0.0859,
      "step": 8150
    },
    {
      "epoch": 13.290113452188006,
      "grad_norm": 0.002996608382090926,
      "learning_rate": 2.2803415108613423e-06,
      "loss": 0.1013,
      "step": 8200
    },
    {
      "epoch": 13.371150729335493,
      "grad_norm": 44.12005615234375,
      "learning_rate": 2.172268453474549e-06,
      "loss": 0.1453,
      "step": 8250
    },
    {
      "epoch": 13.452188006482983,
      "grad_norm": 0.0029613489750772715,
      "learning_rate": 2.0641953960877555e-06,
      "loss": 0.1048,
      "step": 8300
    },
    {
      "epoch": 13.53322528363047,
      "grad_norm": 21.335506439208984,
      "learning_rate": 1.956122338700962e-06,
      "loss": 0.1294,
      "step": 8350
    },
    {
      "epoch": 13.614262560777957,
      "grad_norm": 0.0029605047311633825,
      "learning_rate": 1.8480492813141684e-06,
      "loss": 0.1189,
      "step": 8400
    },
    {
      "epoch": 13.695299837925445,
      "grad_norm": 0.003378233639523387,
      "learning_rate": 1.7399762239273752e-06,
      "loss": 0.1275,
      "step": 8450
    },
    {
      "epoch": 13.776337115072934,
      "grad_norm": 0.0025658791419118643,
      "learning_rate": 1.6319031665405816e-06,
      "loss": 0.0683,
      "step": 8500
    },
    {
      "epoch": 13.857374392220422,
      "grad_norm": 4.104879379272461,
      "learning_rate": 1.523830109153788e-06,
      "loss": 0.0899,
      "step": 8550
    },
    {
      "epoch": 13.938411669367909,
      "grad_norm": 0.004828274715691805,
      "learning_rate": 1.4157570517669947e-06,
      "loss": 0.1147,
      "step": 8600
    },
    {
      "epoch": 14.019448946515396,
      "grad_norm": 6.6091694831848145,
      "learning_rate": 1.307683994380201e-06,
      "loss": 0.0941,
      "step": 8650
    },
    {
      "epoch": 14.100486223662886,
      "grad_norm": 0.39571288228034973,
      "learning_rate": 1.1996109369934076e-06,
      "loss": 0.1096,
      "step": 8700
    },
    {
      "epoch": 14.181523500810373,
      "grad_norm": 0.0027417840901762247,
      "learning_rate": 1.0915378796066142e-06,
      "loss": 0.064,
      "step": 8750
    },
    {
      "epoch": 14.26256077795786,
      "grad_norm": 0.0018171315314248204,
      "learning_rate": 9.834648222198206e-07,
      "loss": 0.076,
      "step": 8800
    },
    {
      "epoch": 14.343598055105348,
      "grad_norm": 5.551008224487305,
      "learning_rate": 8.753917648330273e-07,
      "loss": 0.0844,
      "step": 8850
    },
    {
      "epoch": 14.424635332252837,
      "grad_norm": 0.0016097115585580468,
      "learning_rate": 7.673187074462337e-07,
      "loss": 0.0882,
      "step": 8900
    },
    {
      "epoch": 14.505672609400325,
      "grad_norm": 0.4437810182571411,
      "learning_rate": 6.592456500594402e-07,
      "loss": 0.1195,
      "step": 8950
    },
    {
      "epoch": 14.586709886547812,
      "grad_norm": 0.003474424360319972,
      "learning_rate": 5.511725926726468e-07,
      "loss": 0.0757,
      "step": 9000
    },
    {
      "epoch": 14.6677471636953,
      "grad_norm": 1.267526388168335,
      "learning_rate": 4.4309953528585324e-07,
      "loss": 0.0762,
      "step": 9050
    },
    {
      "epoch": 14.748784440842787,
      "grad_norm": 0.005004836246371269,
      "learning_rate": 3.350264778990598e-07,
      "loss": 0.0729,
      "step": 9100
    },
    {
      "epoch": 14.829821717990276,
      "grad_norm": 3.396172285079956,
      "learning_rate": 2.2695342051226633e-07,
      "loss": 0.102,
      "step": 9150
    },
    {
      "epoch": 14.910858995137763,
      "grad_norm": 0.0064461370930075645,
      "learning_rate": 1.1888036312547284e-07,
      "loss": 0.0676,
      "step": 9200
    },
    {
      "epoch": 14.991896272285251,
      "grad_norm": 0.006061632186174393,
      "learning_rate": 1.0807305738679348e-08,
      "loss": 0.0663,
      "step": 9250
    }
  ],
  "logging_steps": 50,
  "max_steps": 9255,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6190828332870032e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
