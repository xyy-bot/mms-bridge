{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 6170,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08103727714748785,
      "grad_norm": 21.9472713470459,
      "learning_rate": 1.98443579766537e-05,
      "loss": 11.2898,
      "step": 50
    },
    {
      "epoch": 0.1620745542949757,
      "grad_norm": 27.108510971069336,
      "learning_rate": 1.9682230869001297e-05,
      "loss": 4.3924,
      "step": 100
    },
    {
      "epoch": 0.24311183144246354,
      "grad_norm": 31.166362762451172,
      "learning_rate": 1.9520103761348898e-05,
      "loss": 1.8833,
      "step": 150
    },
    {
      "epoch": 0.3241491085899514,
      "grad_norm": 9.019491195678711,
      "learning_rate": 1.93579766536965e-05,
      "loss": 1.6057,
      "step": 200
    },
    {
      "epoch": 0.4051863857374392,
      "grad_norm": 22.04671287536621,
      "learning_rate": 1.91958495460441e-05,
      "loss": 1.2646,
      "step": 250
    },
    {
      "epoch": 0.4862236628849271,
      "grad_norm": 9.227156639099121,
      "learning_rate": 1.90337224383917e-05,
      "loss": 0.9704,
      "step": 300
    },
    {
      "epoch": 0.5672609400324149,
      "grad_norm": 28.564085006713867,
      "learning_rate": 1.8871595330739302e-05,
      "loss": 1.1369,
      "step": 350
    },
    {
      "epoch": 0.6482982171799028,
      "grad_norm": 44.3082160949707,
      "learning_rate": 1.8709468223086903e-05,
      "loss": 1.5977,
      "step": 400
    },
    {
      "epoch": 0.7293354943273906,
      "grad_norm": 5.196005344390869,
      "learning_rate": 1.8547341115434504e-05,
      "loss": 0.9658,
      "step": 450
    },
    {
      "epoch": 0.8103727714748784,
      "grad_norm": 24.28671646118164,
      "learning_rate": 1.83852140077821e-05,
      "loss": 1.0157,
      "step": 500
    },
    {
      "epoch": 0.8914100486223663,
      "grad_norm": 3.3797757625579834,
      "learning_rate": 1.8223086900129702e-05,
      "loss": 1.0195,
      "step": 550
    },
    {
      "epoch": 0.9724473257698542,
      "grad_norm": 11.658802032470703,
      "learning_rate": 1.8060959792477303e-05,
      "loss": 1.2346,
      "step": 600
    },
    {
      "epoch": 1.053484602917342,
      "grad_norm": 12.057384490966797,
      "learning_rate": 1.7898832684824904e-05,
      "loss": 0.9182,
      "step": 650
    },
    {
      "epoch": 1.1345218800648298,
      "grad_norm": 8.008490562438965,
      "learning_rate": 1.7736705577172505e-05,
      "loss": 0.7742,
      "step": 700
    },
    {
      "epoch": 1.2155591572123177,
      "grad_norm": 7.835599899291992,
      "learning_rate": 1.7574578469520106e-05,
      "loss": 0.9977,
      "step": 750
    },
    {
      "epoch": 1.2965964343598055,
      "grad_norm": 1.9940987825393677,
      "learning_rate": 1.7412451361867707e-05,
      "loss": 0.7715,
      "step": 800
    },
    {
      "epoch": 1.3776337115072934,
      "grad_norm": 4.561180114746094,
      "learning_rate": 1.7250324254215308e-05,
      "loss": 0.6572,
      "step": 850
    },
    {
      "epoch": 1.4586709886547813,
      "grad_norm": 13.414559364318848,
      "learning_rate": 1.7088197146562906e-05,
      "loss": 1.2324,
      "step": 900
    },
    {
      "epoch": 1.5397082658022692,
      "grad_norm": 4.673052787780762,
      "learning_rate": 1.6926070038910507e-05,
      "loss": 0.8355,
      "step": 950
    },
    {
      "epoch": 1.620745542949757,
      "grad_norm": 0.11661835759878159,
      "learning_rate": 1.6763942931258108e-05,
      "loss": 1.0088,
      "step": 1000
    },
    {
      "epoch": 1.7017828200972447,
      "grad_norm": 5.016284942626953,
      "learning_rate": 1.660181582360571e-05,
      "loss": 0.9908,
      "step": 1050
    },
    {
      "epoch": 1.7828200972447326,
      "grad_norm": 13.17231273651123,
      "learning_rate": 1.643968871595331e-05,
      "loss": 0.9157,
      "step": 1100
    },
    {
      "epoch": 1.8638573743922204,
      "grad_norm": 8.910652160644531,
      "learning_rate": 1.627756160830091e-05,
      "loss": 0.6782,
      "step": 1150
    },
    {
      "epoch": 1.9448946515397083,
      "grad_norm": 2.976708173751831,
      "learning_rate": 1.611543450064851e-05,
      "loss": 0.95,
      "step": 1200
    },
    {
      "epoch": 2.025931928687196,
      "grad_norm": 0.6582220196723938,
      "learning_rate": 1.5953307392996112e-05,
      "loss": 1.0345,
      "step": 1250
    },
    {
      "epoch": 2.106969205834684,
      "grad_norm": 0.23785406351089478,
      "learning_rate": 1.579118028534371e-05,
      "loss": 0.6777,
      "step": 1300
    },
    {
      "epoch": 2.1880064829821717,
      "grad_norm": 10.884791374206543,
      "learning_rate": 1.562905317769131e-05,
      "loss": 0.9327,
      "step": 1350
    },
    {
      "epoch": 2.2690437601296596,
      "grad_norm": 1.0289632081985474,
      "learning_rate": 1.5466926070038912e-05,
      "loss": 1.0699,
      "step": 1400
    },
    {
      "epoch": 2.3500810372771475,
      "grad_norm": 6.614880084991455,
      "learning_rate": 1.5304798962386513e-05,
      "loss": 0.8176,
      "step": 1450
    },
    {
      "epoch": 2.4311183144246353,
      "grad_norm": 10.780011177062988,
      "learning_rate": 1.5142671854734112e-05,
      "loss": 0.8584,
      "step": 1500
    },
    {
      "epoch": 2.512155591572123,
      "grad_norm": 22.574857711791992,
      "learning_rate": 1.4980544747081713e-05,
      "loss": 0.7654,
      "step": 1550
    },
    {
      "epoch": 2.593192868719611,
      "grad_norm": 9.205833435058594,
      "learning_rate": 1.4818417639429314e-05,
      "loss": 0.7999,
      "step": 1600
    },
    {
      "epoch": 2.674230145867099,
      "grad_norm": 11.723435401916504,
      "learning_rate": 1.4656290531776913e-05,
      "loss": 0.8301,
      "step": 1650
    },
    {
      "epoch": 2.755267423014587,
      "grad_norm": 0.10481880605220795,
      "learning_rate": 1.4494163424124514e-05,
      "loss": 0.5972,
      "step": 1700
    },
    {
      "epoch": 2.8363047001620747,
      "grad_norm": 26.733959197998047,
      "learning_rate": 1.4332036316472115e-05,
      "loss": 0.6462,
      "step": 1750
    },
    {
      "epoch": 2.9173419773095626,
      "grad_norm": 0.1417534053325653,
      "learning_rate": 1.4169909208819716e-05,
      "loss": 0.7604,
      "step": 1800
    },
    {
      "epoch": 2.99837925445705,
      "grad_norm": 18.831253051757812,
      "learning_rate": 1.4007782101167315e-05,
      "loss": 0.8175,
      "step": 1850
    },
    {
      "epoch": 3.079416531604538,
      "grad_norm": 0.186086967587471,
      "learning_rate": 1.3845654993514916e-05,
      "loss": 0.6811,
      "step": 1900
    },
    {
      "epoch": 3.1604538087520258,
      "grad_norm": 15.403879165649414,
      "learning_rate": 1.3683527885862517e-05,
      "loss": 0.6166,
      "step": 1950
    },
    {
      "epoch": 3.2414910858995136,
      "grad_norm": 0.14720334112644196,
      "learning_rate": 1.3521400778210118e-05,
      "loss": 0.4512,
      "step": 2000
    },
    {
      "epoch": 3.3225283630470015,
      "grad_norm": 0.06021721288561821,
      "learning_rate": 1.3359273670557718e-05,
      "loss": 0.9769,
      "step": 2050
    },
    {
      "epoch": 3.4035656401944894,
      "grad_norm": 15.191460609436035,
      "learning_rate": 1.3197146562905319e-05,
      "loss": 0.6684,
      "step": 2100
    },
    {
      "epoch": 3.4846029173419772,
      "grad_norm": 3.617940902709961,
      "learning_rate": 1.303501945525292e-05,
      "loss": 0.5829,
      "step": 2150
    },
    {
      "epoch": 3.565640194489465,
      "grad_norm": 0.011798661202192307,
      "learning_rate": 1.287289234760052e-05,
      "loss": 0.9699,
      "step": 2200
    },
    {
      "epoch": 3.646677471636953,
      "grad_norm": 0.45916056632995605,
      "learning_rate": 1.271076523994812e-05,
      "loss": 0.8236,
      "step": 2250
    },
    {
      "epoch": 3.727714748784441,
      "grad_norm": 11.312223434448242,
      "learning_rate": 1.254863813229572e-05,
      "loss": 0.5853,
      "step": 2300
    },
    {
      "epoch": 3.8087520259319287,
      "grad_norm": 15.959129333496094,
      "learning_rate": 1.2386511024643322e-05,
      "loss": 0.587,
      "step": 2350
    },
    {
      "epoch": 3.8897893030794166,
      "grad_norm": 0.01942524127662182,
      "learning_rate": 1.2224383916990923e-05,
      "loss": 0.7046,
      "step": 2400
    },
    {
      "epoch": 3.9708265802269045,
      "grad_norm": 0.7446726560592651,
      "learning_rate": 1.2062256809338522e-05,
      "loss": 0.7037,
      "step": 2450
    },
    {
      "epoch": 4.051863857374392,
      "grad_norm": 0.6174191832542419,
      "learning_rate": 1.1900129701686123e-05,
      "loss": 0.5487,
      "step": 2500
    },
    {
      "epoch": 4.13290113452188,
      "grad_norm": 13.814152717590332,
      "learning_rate": 1.1738002594033724e-05,
      "loss": 0.3968,
      "step": 2550
    },
    {
      "epoch": 4.213938411669368,
      "grad_norm": 0.09689163416624069,
      "learning_rate": 1.1575875486381325e-05,
      "loss": 0.5986,
      "step": 2600
    },
    {
      "epoch": 4.294975688816856,
      "grad_norm": 0.045294713228940964,
      "learning_rate": 1.1413748378728924e-05,
      "loss": 0.5686,
      "step": 2650
    },
    {
      "epoch": 4.376012965964343,
      "grad_norm": 0.12435457110404968,
      "learning_rate": 1.1251621271076525e-05,
      "loss": 0.7211,
      "step": 2700
    },
    {
      "epoch": 4.457050243111832,
      "grad_norm": 0.011232917197048664,
      "learning_rate": 1.1089494163424126e-05,
      "loss": 0.6371,
      "step": 2750
    },
    {
      "epoch": 4.538087520259319,
      "grad_norm": 14.14526653289795,
      "learning_rate": 1.0927367055771725e-05,
      "loss": 0.4855,
      "step": 2800
    },
    {
      "epoch": 4.6191247974068075,
      "grad_norm": 6.221713542938232,
      "learning_rate": 1.0765239948119326e-05,
      "loss": 0.6318,
      "step": 2850
    },
    {
      "epoch": 4.700162074554295,
      "grad_norm": 0.006470334250479937,
      "learning_rate": 1.0603112840466927e-05,
      "loss": 0.7213,
      "step": 2900
    },
    {
      "epoch": 4.781199351701783,
      "grad_norm": 0.007524636574089527,
      "learning_rate": 1.0440985732814528e-05,
      "loss": 0.5923,
      "step": 2950
    },
    {
      "epoch": 4.862236628849271,
      "grad_norm": 8.825032234191895,
      "learning_rate": 1.0278858625162127e-05,
      "loss": 0.577,
      "step": 3000
    },
    {
      "epoch": 4.943273905996758,
      "grad_norm": 0.023191064596176147,
      "learning_rate": 1.0116731517509728e-05,
      "loss": 0.6599,
      "step": 3050
    },
    {
      "epoch": 5.024311183144246,
      "grad_norm": 18.052350997924805,
      "learning_rate": 9.95460440985733e-06,
      "loss": 0.6478,
      "step": 3100
    },
    {
      "epoch": 5.105348460291734,
      "grad_norm": 13.815155982971191,
      "learning_rate": 9.792477302204928e-06,
      "loss": 0.5907,
      "step": 3150
    },
    {
      "epoch": 5.186385737439222,
      "grad_norm": 0.45748722553253174,
      "learning_rate": 9.63035019455253e-06,
      "loss": 0.5733,
      "step": 3200
    },
    {
      "epoch": 5.26742301458671,
      "grad_norm": 0.006684515625238419,
      "learning_rate": 9.46822308690013e-06,
      "loss": 0.3219,
      "step": 3250
    },
    {
      "epoch": 5.348460291734198,
      "grad_norm": 17.877765655517578,
      "learning_rate": 9.306095979247731e-06,
      "loss": 0.4845,
      "step": 3300
    },
    {
      "epoch": 5.429497568881685,
      "grad_norm": 28.274965286254883,
      "learning_rate": 9.14396887159533e-06,
      "loss": 0.6034,
      "step": 3350
    },
    {
      "epoch": 5.510534846029174,
      "grad_norm": 0.009898953139781952,
      "learning_rate": 8.981841763942932e-06,
      "loss": 0.5336,
      "step": 3400
    },
    {
      "epoch": 5.591572123176661,
      "grad_norm": 11.263628005981445,
      "learning_rate": 8.819714656290533e-06,
      "loss": 0.6542,
      "step": 3450
    },
    {
      "epoch": 5.672609400324149,
      "grad_norm": 16.438505172729492,
      "learning_rate": 8.657587548638134e-06,
      "loss": 0.5817,
      "step": 3500
    },
    {
      "epoch": 5.753646677471637,
      "grad_norm": 26.47218132019043,
      "learning_rate": 8.495460440985733e-06,
      "loss": 0.5003,
      "step": 3550
    },
    {
      "epoch": 5.834683954619125,
      "grad_norm": 0.006345566362142563,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.4619,
      "step": 3600
    },
    {
      "epoch": 5.915721231766613,
      "grad_norm": 0.018330279737710953,
      "learning_rate": 8.171206225680935e-06,
      "loss": 0.4275,
      "step": 3650
    },
    {
      "epoch": 5.9967585089141,
      "grad_norm": 0.04257885739207268,
      "learning_rate": 8.009079118028536e-06,
      "loss": 0.6214,
      "step": 3700
    },
    {
      "epoch": 6.077795786061588,
      "grad_norm": 20.509050369262695,
      "learning_rate": 7.846952010376135e-06,
      "loss": 0.4524,
      "step": 3750
    },
    {
      "epoch": 6.158833063209076,
      "grad_norm": 0.18252532184123993,
      "learning_rate": 7.684824902723736e-06,
      "loss": 0.3248,
      "step": 3800
    },
    {
      "epoch": 6.239870340356564,
      "grad_norm": 0.0048753353767097,
      "learning_rate": 7.522697795071337e-06,
      "loss": 0.4569,
      "step": 3850
    },
    {
      "epoch": 6.3209076175040515,
      "grad_norm": 0.013965539634227753,
      "learning_rate": 7.360570687418938e-06,
      "loss": 0.3908,
      "step": 3900
    },
    {
      "epoch": 6.40194489465154,
      "grad_norm": 9.041887283325195,
      "learning_rate": 7.198443579766538e-06,
      "loss": 0.3962,
      "step": 3950
    },
    {
      "epoch": 6.482982171799027,
      "grad_norm": 20.25008201599121,
      "learning_rate": 7.036316472114139e-06,
      "loss": 0.4342,
      "step": 4000
    },
    {
      "epoch": 6.564019448946516,
      "grad_norm": 0.004327784758061171,
      "learning_rate": 6.874189364461739e-06,
      "loss": 0.7038,
      "step": 4050
    },
    {
      "epoch": 6.645056726094003,
      "grad_norm": 0.04899563267827034,
      "learning_rate": 6.712062256809338e-06,
      "loss": 0.4599,
      "step": 4100
    },
    {
      "epoch": 6.726094003241491,
      "grad_norm": 0.007913174107670784,
      "learning_rate": 6.549935149156939e-06,
      "loss": 0.5437,
      "step": 4150
    },
    {
      "epoch": 6.807131280388979,
      "grad_norm": 0.002919939812272787,
      "learning_rate": 6.387808041504539e-06,
      "loss": 0.3976,
      "step": 4200
    },
    {
      "epoch": 6.888168557536467,
      "grad_norm": 31.77842140197754,
      "learning_rate": 6.22568093385214e-06,
      "loss": 0.5312,
      "step": 4250
    },
    {
      "epoch": 6.9692058346839545,
      "grad_norm": 14.510832786560059,
      "learning_rate": 6.06355382619974e-06,
      "loss": 0.5583,
      "step": 4300
    },
    {
      "epoch": 7.050243111831443,
      "grad_norm": 0.004263837821781635,
      "learning_rate": 5.901426718547341e-06,
      "loss": 0.3936,
      "step": 4350
    },
    {
      "epoch": 7.13128038897893,
      "grad_norm": 0.02126963622868061,
      "learning_rate": 5.7392996108949415e-06,
      "loss": 0.4477,
      "step": 4400
    },
    {
      "epoch": 7.212317666126419,
      "grad_norm": 17.137178421020508,
      "learning_rate": 5.577172503242542e-06,
      "loss": 0.3636,
      "step": 4450
    },
    {
      "epoch": 7.293354943273906,
      "grad_norm": 0.010482382960617542,
      "learning_rate": 5.4150453955901425e-06,
      "loss": 0.3552,
      "step": 4500
    },
    {
      "epoch": 7.374392220421393,
      "grad_norm": 0.006476746406406164,
      "learning_rate": 5.2529182879377435e-06,
      "loss": 0.6187,
      "step": 4550
    },
    {
      "epoch": 7.455429497568882,
      "grad_norm": 10.71618366241455,
      "learning_rate": 5.090791180285344e-06,
      "loss": 0.2964,
      "step": 4600
    },
    {
      "epoch": 7.536466774716369,
      "grad_norm": 11.344244003295898,
      "learning_rate": 4.9286640726329446e-06,
      "loss": 0.4059,
      "step": 4650
    },
    {
      "epoch": 7.6175040518638575,
      "grad_norm": 0.0058288113214075565,
      "learning_rate": 4.7665369649805455e-06,
      "loss": 0.4164,
      "step": 4700
    },
    {
      "epoch": 7.698541329011345,
      "grad_norm": 20.795705795288086,
      "learning_rate": 4.604409857328146e-06,
      "loss": 0.5684,
      "step": 4750
    },
    {
      "epoch": 7.779578606158833,
      "grad_norm": 0.003721480257809162,
      "learning_rate": 4.442282749675746e-06,
      "loss": 0.3156,
      "step": 4800
    },
    {
      "epoch": 7.860615883306321,
      "grad_norm": 31.330123901367188,
      "learning_rate": 4.280155642023347e-06,
      "loss": 0.5103,
      "step": 4850
    },
    {
      "epoch": 7.941653160453809,
      "grad_norm": 0.007842437364161015,
      "learning_rate": 4.118028534370947e-06,
      "loss": 0.5046,
      "step": 4900
    },
    {
      "epoch": 8.022690437601296,
      "grad_norm": 0.13805800676345825,
      "learning_rate": 3.955901426718548e-06,
      "loss": 0.2099,
      "step": 4950
    },
    {
      "epoch": 8.103727714748784,
      "grad_norm": 0.002761813346296549,
      "learning_rate": 3.793774319066148e-06,
      "loss": 0.2819,
      "step": 5000
    },
    {
      "epoch": 8.184764991896273,
      "grad_norm": 0.004211612045764923,
      "learning_rate": 3.6316472114137484e-06,
      "loss": 0.3253,
      "step": 5050
    },
    {
      "epoch": 8.26580226904376,
      "grad_norm": 25.41543197631836,
      "learning_rate": 3.469520103761349e-06,
      "loss": 0.3769,
      "step": 5100
    },
    {
      "epoch": 8.346839546191248,
      "grad_norm": 0.014010039158165455,
      "learning_rate": 3.3073929961089495e-06,
      "loss": 0.3699,
      "step": 5150
    },
    {
      "epoch": 8.427876823338735,
      "grad_norm": 32.33671188354492,
      "learning_rate": 3.14526588845655e-06,
      "loss": 0.4917,
      "step": 5200
    },
    {
      "epoch": 8.508914100486223,
      "grad_norm": 0.007593883667141199,
      "learning_rate": 2.9831387808041506e-06,
      "loss": 0.3912,
      "step": 5250
    },
    {
      "epoch": 8.589951377633712,
      "grad_norm": 3.987424850463867,
      "learning_rate": 2.821011673151751e-06,
      "loss": 0.2949,
      "step": 5300
    },
    {
      "epoch": 8.6709886547812,
      "grad_norm": 0.060557860881090164,
      "learning_rate": 2.6588845654993516e-06,
      "loss": 0.3818,
      "step": 5350
    },
    {
      "epoch": 8.752025931928687,
      "grad_norm": 0.007369696162641048,
      "learning_rate": 2.496757457846952e-06,
      "loss": 0.4108,
      "step": 5400
    },
    {
      "epoch": 8.833063209076174,
      "grad_norm": 0.006323221605271101,
      "learning_rate": 2.3346303501945527e-06,
      "loss": 0.4213,
      "step": 5450
    },
    {
      "epoch": 8.914100486223663,
      "grad_norm": 0.012201662175357342,
      "learning_rate": 2.1725032425421532e-06,
      "loss": 0.2657,
      "step": 5500
    },
    {
      "epoch": 8.995137763371151,
      "grad_norm": 0.004643070045858622,
      "learning_rate": 2.0103761348897538e-06,
      "loss": 0.4725,
      "step": 5550
    },
    {
      "epoch": 9.076175040518638,
      "grad_norm": 0.005353393033146858,
      "learning_rate": 1.8482490272373543e-06,
      "loss": 0.2213,
      "step": 5600
    },
    {
      "epoch": 9.157212317666126,
      "grad_norm": 0.01291931513696909,
      "learning_rate": 1.6861219195849549e-06,
      "loss": 0.3738,
      "step": 5650
    },
    {
      "epoch": 9.238249594813615,
      "grad_norm": 9.97656536102295,
      "learning_rate": 1.5239948119325554e-06,
      "loss": 0.3721,
      "step": 5700
    },
    {
      "epoch": 9.319286871961102,
      "grad_norm": 0.027481526136398315,
      "learning_rate": 1.3618677042801557e-06,
      "loss": 0.3895,
      "step": 5750
    },
    {
      "epoch": 9.40032414910859,
      "grad_norm": 0.0031070797704160213,
      "learning_rate": 1.1997405966277562e-06,
      "loss": 0.3463,
      "step": 5800
    },
    {
      "epoch": 9.481361426256077,
      "grad_norm": 0.010724063031375408,
      "learning_rate": 1.0376134889753568e-06,
      "loss": 0.3917,
      "step": 5850
    },
    {
      "epoch": 9.562398703403566,
      "grad_norm": 0.003949180245399475,
      "learning_rate": 8.754863813229572e-07,
      "loss": 0.3602,
      "step": 5900
    },
    {
      "epoch": 9.643435980551054,
      "grad_norm": 0.025316407904028893,
      "learning_rate": 7.133592736705577e-07,
      "loss": 0.3394,
      "step": 5950
    },
    {
      "epoch": 9.724473257698541,
      "grad_norm": 0.011437992565333843,
      "learning_rate": 5.512321660181583e-07,
      "loss": 0.2411,
      "step": 6000
    },
    {
      "epoch": 9.805510534846029,
      "grad_norm": 9.151250839233398,
      "learning_rate": 3.8910505836575877e-07,
      "loss": 0.2198,
      "step": 6050
    },
    {
      "epoch": 9.886547811993516,
      "grad_norm": 8.19735050201416,
      "learning_rate": 2.2697795071335928e-07,
      "loss": 0.3425,
      "step": 6100
    },
    {
      "epoch": 9.967585089141005,
      "grad_norm": 0.06623554974794388,
      "learning_rate": 6.48508430609598e-08,
      "loss": 0.3125,
      "step": 6150
    }
  ],
  "logging_steps": 50,
  "max_steps": 6170,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0783884666623328e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
