{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 6170,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08103727714748785,
      "grad_norm": 20.534868240356445,
      "learning_rate": 1.98443579766537e-05,
      "loss": 11.0742,
      "step": 50
    },
    {
      "epoch": 0.1620745542949757,
      "grad_norm": 28.934370040893555,
      "learning_rate": 1.9682230869001297e-05,
      "loss": 4.1659,
      "step": 100
    },
    {
      "epoch": 0.24311183144246354,
      "grad_norm": 28.18088150024414,
      "learning_rate": 1.9520103761348898e-05,
      "loss": 1.8026,
      "step": 150
    },
    {
      "epoch": 0.3241491085899514,
      "grad_norm": 9.970836639404297,
      "learning_rate": 1.93579766536965e-05,
      "loss": 1.5617,
      "step": 200
    },
    {
      "epoch": 0.4051863857374392,
      "grad_norm": 18.733978271484375,
      "learning_rate": 1.91958495460441e-05,
      "loss": 1.2439,
      "step": 250
    },
    {
      "epoch": 0.4862236628849271,
      "grad_norm": 10.656719207763672,
      "learning_rate": 1.90337224383917e-05,
      "loss": 0.9716,
      "step": 300
    },
    {
      "epoch": 0.5672609400324149,
      "grad_norm": 37.777652740478516,
      "learning_rate": 1.8871595330739302e-05,
      "loss": 1.1439,
      "step": 350
    },
    {
      "epoch": 0.6482982171799028,
      "grad_norm": 25.12544059753418,
      "learning_rate": 1.8709468223086903e-05,
      "loss": 1.588,
      "step": 400
    },
    {
      "epoch": 0.7293354943273906,
      "grad_norm": 4.249560356140137,
      "learning_rate": 1.8547341115434504e-05,
      "loss": 0.9599,
      "step": 450
    },
    {
      "epoch": 0.8103727714748784,
      "grad_norm": 24.096372604370117,
      "learning_rate": 1.83852140077821e-05,
      "loss": 1.0033,
      "step": 500
    },
    {
      "epoch": 0.8914100486223663,
      "grad_norm": 1.2118983268737793,
      "learning_rate": 1.8223086900129702e-05,
      "loss": 1.0105,
      "step": 550
    },
    {
      "epoch": 0.9724473257698542,
      "grad_norm": 9.829499244689941,
      "learning_rate": 1.8060959792477303e-05,
      "loss": 1.2194,
      "step": 600
    },
    {
      "epoch": 1.053484602917342,
      "grad_norm": 6.599553108215332,
      "learning_rate": 1.7898832684824904e-05,
      "loss": 0.9073,
      "step": 650
    },
    {
      "epoch": 1.1345218800648298,
      "grad_norm": 6.55049991607666,
      "learning_rate": 1.7736705577172505e-05,
      "loss": 0.7834,
      "step": 700
    },
    {
      "epoch": 1.2155591572123177,
      "grad_norm": 7.079432964324951,
      "learning_rate": 1.7574578469520106e-05,
      "loss": 0.9852,
      "step": 750
    },
    {
      "epoch": 1.2965964343598055,
      "grad_norm": 3.475952625274658,
      "learning_rate": 1.7412451361867707e-05,
      "loss": 0.7755,
      "step": 800
    },
    {
      "epoch": 1.3776337115072934,
      "grad_norm": 2.680104970932007,
      "learning_rate": 1.7250324254215308e-05,
      "loss": 0.6497,
      "step": 850
    },
    {
      "epoch": 1.4586709886547813,
      "grad_norm": 13.648828506469727,
      "learning_rate": 1.7088197146562906e-05,
      "loss": 1.2308,
      "step": 900
    },
    {
      "epoch": 1.5397082658022692,
      "grad_norm": 4.652548313140869,
      "learning_rate": 1.6926070038910507e-05,
      "loss": 0.8373,
      "step": 950
    },
    {
      "epoch": 1.620745542949757,
      "grad_norm": 0.8712043762207031,
      "learning_rate": 1.6763942931258108e-05,
      "loss": 1.0119,
      "step": 1000
    },
    {
      "epoch": 1.7017828200972447,
      "grad_norm": 1.0714454650878906,
      "learning_rate": 1.660181582360571e-05,
      "loss": 0.997,
      "step": 1050
    },
    {
      "epoch": 1.7828200972447326,
      "grad_norm": 12.333901405334473,
      "learning_rate": 1.643968871595331e-05,
      "loss": 0.9191,
      "step": 1100
    },
    {
      "epoch": 1.8638573743922204,
      "grad_norm": 9.894163131713867,
      "learning_rate": 1.627756160830091e-05,
      "loss": 0.6587,
      "step": 1150
    },
    {
      "epoch": 1.9448946515397083,
      "grad_norm": 11.60566234588623,
      "learning_rate": 1.611543450064851e-05,
      "loss": 0.9315,
      "step": 1200
    },
    {
      "epoch": 2.025931928687196,
      "grad_norm": 3.94277024269104,
      "learning_rate": 1.5953307392996112e-05,
      "loss": 1.0303,
      "step": 1250
    },
    {
      "epoch": 2.106969205834684,
      "grad_norm": 0.09822893142700195,
      "learning_rate": 1.579118028534371e-05,
      "loss": 0.6904,
      "step": 1300
    },
    {
      "epoch": 2.1880064829821717,
      "grad_norm": 11.730412483215332,
      "learning_rate": 1.562905317769131e-05,
      "loss": 0.9152,
      "step": 1350
    },
    {
      "epoch": 2.2690437601296596,
      "grad_norm": 0.18962474167346954,
      "learning_rate": 1.5466926070038912e-05,
      "loss": 1.0798,
      "step": 1400
    },
    {
      "epoch": 2.3500810372771475,
      "grad_norm": 4.189286708831787,
      "learning_rate": 1.5304798962386513e-05,
      "loss": 0.7804,
      "step": 1450
    },
    {
      "epoch": 2.4311183144246353,
      "grad_norm": 8.617086410522461,
      "learning_rate": 1.5142671854734112e-05,
      "loss": 0.8457,
      "step": 1500
    },
    {
      "epoch": 2.512155591572123,
      "grad_norm": 21.65705108642578,
      "learning_rate": 1.4980544747081713e-05,
      "loss": 0.7321,
      "step": 1550
    },
    {
      "epoch": 2.593192868719611,
      "grad_norm": 4.366038799285889,
      "learning_rate": 1.4818417639429314e-05,
      "loss": 0.8003,
      "step": 1600
    },
    {
      "epoch": 2.674230145867099,
      "grad_norm": 12.050867080688477,
      "learning_rate": 1.4656290531776913e-05,
      "loss": 0.8195,
      "step": 1650
    },
    {
      "epoch": 2.755267423014587,
      "grad_norm": 0.49797743558883667,
      "learning_rate": 1.4494163424124514e-05,
      "loss": 0.6052,
      "step": 1700
    },
    {
      "epoch": 2.8363047001620747,
      "grad_norm": 16.808135986328125,
      "learning_rate": 1.4332036316472115e-05,
      "loss": 0.6312,
      "step": 1750
    },
    {
      "epoch": 2.9173419773095626,
      "grad_norm": 0.041815340518951416,
      "learning_rate": 1.4169909208819716e-05,
      "loss": 0.7748,
      "step": 1800
    },
    {
      "epoch": 2.99837925445705,
      "grad_norm": 18.73137855529785,
      "learning_rate": 1.4007782101167315e-05,
      "loss": 0.8115,
      "step": 1850
    },
    {
      "epoch": 3.079416531604538,
      "grad_norm": 0.07282315939664841,
      "learning_rate": 1.3845654993514916e-05,
      "loss": 0.6925,
      "step": 1900
    },
    {
      "epoch": 3.1604538087520258,
      "grad_norm": 13.515141487121582,
      "learning_rate": 1.3683527885862517e-05,
      "loss": 0.614,
      "step": 1950
    },
    {
      "epoch": 3.2414910858995136,
      "grad_norm": 4.509308338165283,
      "learning_rate": 1.3521400778210118e-05,
      "loss": 0.4528,
      "step": 2000
    },
    {
      "epoch": 3.3225283630470015,
      "grad_norm": 0.07000915706157684,
      "learning_rate": 1.3359273670557718e-05,
      "loss": 0.9774,
      "step": 2050
    },
    {
      "epoch": 3.4035656401944894,
      "grad_norm": 14.2468900680542,
      "learning_rate": 1.3197146562905319e-05,
      "loss": 0.655,
      "step": 2100
    },
    {
      "epoch": 3.4846029173419772,
      "grad_norm": 3.485729217529297,
      "learning_rate": 1.303501945525292e-05,
      "loss": 0.589,
      "step": 2150
    },
    {
      "epoch": 3.565640194489465,
      "grad_norm": 0.010548991151154041,
      "learning_rate": 1.287289234760052e-05,
      "loss": 0.9752,
      "step": 2200
    },
    {
      "epoch": 3.646677471636953,
      "grad_norm": 0.24929474294185638,
      "learning_rate": 1.271076523994812e-05,
      "loss": 0.8244,
      "step": 2250
    },
    {
      "epoch": 3.727714748784441,
      "grad_norm": 9.999799728393555,
      "learning_rate": 1.254863813229572e-05,
      "loss": 0.5657,
      "step": 2300
    },
    {
      "epoch": 3.8087520259319287,
      "grad_norm": 16.887744903564453,
      "learning_rate": 1.2386511024643322e-05,
      "loss": 0.5901,
      "step": 2350
    },
    {
      "epoch": 3.8897893030794166,
      "grad_norm": 0.035296060144901276,
      "learning_rate": 1.2224383916990923e-05,
      "loss": 0.7013,
      "step": 2400
    },
    {
      "epoch": 3.9708265802269045,
      "grad_norm": 0.2530001401901245,
      "learning_rate": 1.2062256809338522e-05,
      "loss": 0.7056,
      "step": 2450
    },
    {
      "epoch": 4.051863857374392,
      "grad_norm": 0.585629940032959,
      "learning_rate": 1.1900129701686123e-05,
      "loss": 0.5537,
      "step": 2500
    },
    {
      "epoch": 4.13290113452188,
      "grad_norm": 14.07690715789795,
      "learning_rate": 1.1738002594033724e-05,
      "loss": 0.3924,
      "step": 2550
    },
    {
      "epoch": 4.213938411669368,
      "grad_norm": 1.167314887046814,
      "learning_rate": 1.1575875486381325e-05,
      "loss": 0.587,
      "step": 2600
    },
    {
      "epoch": 4.294975688816856,
      "grad_norm": 0.027287760749459267,
      "learning_rate": 1.1413748378728924e-05,
      "loss": 0.5617,
      "step": 2650
    },
    {
      "epoch": 4.376012965964343,
      "grad_norm": 0.06617321819067001,
      "learning_rate": 1.1251621271076525e-05,
      "loss": 0.7366,
      "step": 2700
    },
    {
      "epoch": 4.457050243111832,
      "grad_norm": 0.012553835287690163,
      "learning_rate": 1.1089494163424126e-05,
      "loss": 0.6418,
      "step": 2750
    },
    {
      "epoch": 4.538087520259319,
      "grad_norm": 13.952760696411133,
      "learning_rate": 1.0927367055771725e-05,
      "loss": 0.4835,
      "step": 2800
    },
    {
      "epoch": 4.6191247974068075,
      "grad_norm": 8.393543243408203,
      "learning_rate": 1.0765239948119326e-05,
      "loss": 0.6315,
      "step": 2850
    },
    {
      "epoch": 4.700162074554295,
      "grad_norm": 0.015050218440592289,
      "learning_rate": 1.0603112840466927e-05,
      "loss": 0.7098,
      "step": 2900
    },
    {
      "epoch": 4.781199351701783,
      "grad_norm": 0.012262362986803055,
      "learning_rate": 1.0440985732814528e-05,
      "loss": 0.5815,
      "step": 2950
    },
    {
      "epoch": 4.862236628849271,
      "grad_norm": 9.138493537902832,
      "learning_rate": 1.0278858625162127e-05,
      "loss": 0.5836,
      "step": 3000
    },
    {
      "epoch": 4.943273905996758,
      "grad_norm": 0.03187771514058113,
      "learning_rate": 1.0116731517509728e-05,
      "loss": 0.6628,
      "step": 3050
    },
    {
      "epoch": 5.024311183144246,
      "grad_norm": 20.737987518310547,
      "learning_rate": 9.95460440985733e-06,
      "loss": 0.6411,
      "step": 3100
    },
    {
      "epoch": 5.105348460291734,
      "grad_norm": 12.458742141723633,
      "learning_rate": 9.792477302204928e-06,
      "loss": 0.5744,
      "step": 3150
    },
    {
      "epoch": 5.186385737439222,
      "grad_norm": 0.08027224242687225,
      "learning_rate": 9.63035019455253e-06,
      "loss": 0.5949,
      "step": 3200
    },
    {
      "epoch": 5.26742301458671,
      "grad_norm": 0.007375407498329878,
      "learning_rate": 9.46822308690013e-06,
      "loss": 0.3091,
      "step": 3250
    },
    {
      "epoch": 5.348460291734198,
      "grad_norm": 16.932832717895508,
      "learning_rate": 9.306095979247731e-06,
      "loss": 0.4888,
      "step": 3300
    },
    {
      "epoch": 5.429497568881685,
      "grad_norm": 23.480018615722656,
      "learning_rate": 9.14396887159533e-06,
      "loss": 0.5977,
      "step": 3350
    },
    {
      "epoch": 5.510534846029174,
      "grad_norm": 0.0199907124042511,
      "learning_rate": 8.981841763942932e-06,
      "loss": 0.5256,
      "step": 3400
    },
    {
      "epoch": 5.591572123176661,
      "grad_norm": 10.928119659423828,
      "learning_rate": 8.819714656290533e-06,
      "loss": 0.6622,
      "step": 3450
    },
    {
      "epoch": 5.672609400324149,
      "grad_norm": 11.765620231628418,
      "learning_rate": 8.657587548638134e-06,
      "loss": 0.5832,
      "step": 3500
    },
    {
      "epoch": 5.753646677471637,
      "grad_norm": 25.468358993530273,
      "learning_rate": 8.495460440985733e-06,
      "loss": 0.4974,
      "step": 3550
    },
    {
      "epoch": 5.834683954619125,
      "grad_norm": 0.018932469189167023,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.4733,
      "step": 3600
    },
    {
      "epoch": 5.915721231766613,
      "grad_norm": 0.011930400505661964,
      "learning_rate": 8.171206225680935e-06,
      "loss": 0.4351,
      "step": 3650
    },
    {
      "epoch": 5.9967585089141,
      "grad_norm": 0.026128677651286125,
      "learning_rate": 8.009079118028536e-06,
      "loss": 0.6197,
      "step": 3700
    },
    {
      "epoch": 6.077795786061588,
      "grad_norm": 21.145427703857422,
      "learning_rate": 7.846952010376135e-06,
      "loss": 0.4452,
      "step": 3750
    },
    {
      "epoch": 6.158833063209076,
      "grad_norm": 0.1680900901556015,
      "learning_rate": 7.684824902723736e-06,
      "loss": 0.3116,
      "step": 3800
    },
    {
      "epoch": 6.239870340356564,
      "grad_norm": 0.004892183467745781,
      "learning_rate": 7.522697795071337e-06,
      "loss": 0.4628,
      "step": 3850
    },
    {
      "epoch": 6.3209076175040515,
      "grad_norm": 0.00900799036026001,
      "learning_rate": 7.360570687418938e-06,
      "loss": 0.3878,
      "step": 3900
    },
    {
      "epoch": 6.40194489465154,
      "grad_norm": 8.748283386230469,
      "learning_rate": 7.198443579766538e-06,
      "loss": 0.3924,
      "step": 3950
    },
    {
      "epoch": 6.482982171799027,
      "grad_norm": 32.58213806152344,
      "learning_rate": 7.036316472114139e-06,
      "loss": 0.4474,
      "step": 4000
    },
    {
      "epoch": 6.564019448946516,
      "grad_norm": 0.008894621394574642,
      "learning_rate": 6.874189364461739e-06,
      "loss": 0.6921,
      "step": 4050
    },
    {
      "epoch": 6.645056726094003,
      "grad_norm": 0.0065592508763074875,
      "learning_rate": 6.712062256809338e-06,
      "loss": 0.4614,
      "step": 4100
    },
    {
      "epoch": 6.726094003241491,
      "grad_norm": 0.008911884389817715,
      "learning_rate": 6.549935149156939e-06,
      "loss": 0.5386,
      "step": 4150
    },
    {
      "epoch": 6.807131280388979,
      "grad_norm": 0.004649042617529631,
      "learning_rate": 6.387808041504539e-06,
      "loss": 0.4087,
      "step": 4200
    },
    {
      "epoch": 6.888168557536467,
      "grad_norm": 25.160539627075195,
      "learning_rate": 6.22568093385214e-06,
      "loss": 0.5175,
      "step": 4250
    },
    {
      "epoch": 6.9692058346839545,
      "grad_norm": 16.682706832885742,
      "learning_rate": 6.06355382619974e-06,
      "loss": 0.5507,
      "step": 4300
    },
    {
      "epoch": 7.050243111831443,
      "grad_norm": 0.0054119243286550045,
      "learning_rate": 5.901426718547341e-06,
      "loss": 0.4001,
      "step": 4350
    },
    {
      "epoch": 7.13128038897893,
      "grad_norm": 0.05989784374833107,
      "learning_rate": 5.7392996108949415e-06,
      "loss": 0.4494,
      "step": 4400
    },
    {
      "epoch": 7.212317666126419,
      "grad_norm": 11.971051216125488,
      "learning_rate": 5.577172503242542e-06,
      "loss": 0.3583,
      "step": 4450
    },
    {
      "epoch": 7.293354943273906,
      "grad_norm": 0.013342625461518764,
      "learning_rate": 5.4150453955901425e-06,
      "loss": 0.3519,
      "step": 4500
    },
    {
      "epoch": 7.374392220421393,
      "grad_norm": 0.012657814659178257,
      "learning_rate": 5.2529182879377435e-06,
      "loss": 0.6174,
      "step": 4550
    },
    {
      "epoch": 7.455429497568882,
      "grad_norm": 9.86324405670166,
      "learning_rate": 5.090791180285344e-06,
      "loss": 0.3073,
      "step": 4600
    },
    {
      "epoch": 7.536466774716369,
      "grad_norm": 18.526458740234375,
      "learning_rate": 4.9286640726329446e-06,
      "loss": 0.3986,
      "step": 4650
    },
    {
      "epoch": 7.6175040518638575,
      "grad_norm": 0.0038726513739675283,
      "learning_rate": 4.7665369649805455e-06,
      "loss": 0.4093,
      "step": 4700
    },
    {
      "epoch": 7.698541329011345,
      "grad_norm": 22.212038040161133,
      "learning_rate": 4.604409857328146e-06,
      "loss": 0.555,
      "step": 4750
    },
    {
      "epoch": 7.779578606158833,
      "grad_norm": 0.0034091370180249214,
      "learning_rate": 4.442282749675746e-06,
      "loss": 0.312,
      "step": 4800
    },
    {
      "epoch": 7.860615883306321,
      "grad_norm": 36.168365478515625,
      "learning_rate": 4.280155642023347e-06,
      "loss": 0.5058,
      "step": 4850
    },
    {
      "epoch": 7.941653160453809,
      "grad_norm": 0.003216926474124193,
      "learning_rate": 4.118028534370947e-06,
      "loss": 0.5053,
      "step": 4900
    },
    {
      "epoch": 8.022690437601296,
      "grad_norm": 0.0577310174703598,
      "learning_rate": 3.955901426718548e-06,
      "loss": 0.22,
      "step": 4950
    },
    {
      "epoch": 8.103727714748784,
      "grad_norm": 0.003057255642488599,
      "learning_rate": 3.793774319066148e-06,
      "loss": 0.2838,
      "step": 5000
    },
    {
      "epoch": 8.184764991896273,
      "grad_norm": 0.008508558385074139,
      "learning_rate": 3.6316472114137484e-06,
      "loss": 0.3268,
      "step": 5050
    },
    {
      "epoch": 8.26580226904376,
      "grad_norm": 32.81235885620117,
      "learning_rate": 3.469520103761349e-06,
      "loss": 0.3673,
      "step": 5100
    },
    {
      "epoch": 8.346839546191248,
      "grad_norm": 0.012710300274193287,
      "learning_rate": 3.3073929961089495e-06,
      "loss": 0.3618,
      "step": 5150
    },
    {
      "epoch": 8.427876823338735,
      "grad_norm": 22.826351165771484,
      "learning_rate": 3.14526588845655e-06,
      "loss": 0.505,
      "step": 5200
    },
    {
      "epoch": 8.508914100486223,
      "grad_norm": 0.027386866509914398,
      "learning_rate": 2.9831387808041506e-06,
      "loss": 0.3865,
      "step": 5250
    },
    {
      "epoch": 8.589951377633712,
      "grad_norm": 4.327084064483643,
      "learning_rate": 2.821011673151751e-06,
      "loss": 0.289,
      "step": 5300
    },
    {
      "epoch": 8.6709886547812,
      "grad_norm": 0.1940198689699173,
      "learning_rate": 2.6588845654993516e-06,
      "loss": 0.3685,
      "step": 5350
    },
    {
      "epoch": 8.752025931928687,
      "grad_norm": 0.003384372917935252,
      "learning_rate": 2.496757457846952e-06,
      "loss": 0.4127,
      "step": 5400
    },
    {
      "epoch": 8.833063209076174,
      "grad_norm": 0.004727901425212622,
      "learning_rate": 2.3346303501945527e-06,
      "loss": 0.4198,
      "step": 5450
    },
    {
      "epoch": 8.914100486223663,
      "grad_norm": 0.00999272707849741,
      "learning_rate": 2.1725032425421532e-06,
      "loss": 0.2647,
      "step": 5500
    },
    {
      "epoch": 8.995137763371151,
      "grad_norm": 0.011394037865102291,
      "learning_rate": 2.0103761348897538e-06,
      "loss": 0.4685,
      "step": 5550
    },
    {
      "epoch": 9.076175040518638,
      "grad_norm": 0.0045944624580442905,
      "learning_rate": 1.8482490272373543e-06,
      "loss": 0.2127,
      "step": 5600
    },
    {
      "epoch": 9.157212317666126,
      "grad_norm": 0.006031414028257132,
      "learning_rate": 1.6861219195849549e-06,
      "loss": 0.3856,
      "step": 5650
    },
    {
      "epoch": 9.238249594813615,
      "grad_norm": 10.696894645690918,
      "learning_rate": 1.5239948119325554e-06,
      "loss": 0.3579,
      "step": 5700
    },
    {
      "epoch": 9.319286871961102,
      "grad_norm": 0.014108468778431416,
      "learning_rate": 1.3618677042801557e-06,
      "loss": 0.3872,
      "step": 5750
    },
    {
      "epoch": 9.40032414910859,
      "grad_norm": 0.012258557602763176,
      "learning_rate": 1.1997405966277562e-06,
      "loss": 0.3423,
      "step": 5800
    },
    {
      "epoch": 9.481361426256077,
      "grad_norm": 0.02774714305996895,
      "learning_rate": 1.0376134889753568e-06,
      "loss": 0.3969,
      "step": 5850
    },
    {
      "epoch": 9.562398703403566,
      "grad_norm": 0.004529946483671665,
      "learning_rate": 8.754863813229572e-07,
      "loss": 0.3351,
      "step": 5900
    },
    {
      "epoch": 9.643435980551054,
      "grad_norm": 0.018516600131988525,
      "learning_rate": 7.133592736705577e-07,
      "loss": 0.3434,
      "step": 5950
    },
    {
      "epoch": 9.724473257698541,
      "grad_norm": 0.01566167175769806,
      "learning_rate": 5.512321660181583e-07,
      "loss": 0.2382,
      "step": 6000
    },
    {
      "epoch": 9.805510534846029,
      "grad_norm": 7.161014080047607,
      "learning_rate": 3.8910505836575877e-07,
      "loss": 0.2101,
      "step": 6050
    },
    {
      "epoch": 9.886547811993516,
      "grad_norm": 7.795085430145264,
      "learning_rate": 2.2697795071335928e-07,
      "loss": 0.3375,
      "step": 6100
    },
    {
      "epoch": 9.967585089141005,
      "grad_norm": 0.022187093272805214,
      "learning_rate": 6.48508430609598e-08,
      "loss": 0.3164,
      "step": 6150
    }
  ],
  "logging_steps": 50,
  "max_steps": 6170,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0793885555246688e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
