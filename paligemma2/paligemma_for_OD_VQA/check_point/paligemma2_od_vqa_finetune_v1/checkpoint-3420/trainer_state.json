{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.971553610503282,
  "eval_steps": 500,
  "global_step": 3420,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14587892049598833,
      "grad_norm": 13.774483680725098,
      "learning_rate": 1.9719133996489176e-05,
      "loss": 10.8707,
      "step": 50
    },
    {
      "epoch": 0.29175784099197666,
      "grad_norm": 24.29189109802246,
      "learning_rate": 1.9426565242832066e-05,
      "loss": 4.0289,
      "step": 100
    },
    {
      "epoch": 0.437636761487965,
      "grad_norm": 19.703859329223633,
      "learning_rate": 1.9133996489174957e-05,
      "loss": 2.0296,
      "step": 150
    },
    {
      "epoch": 0.5835156819839533,
      "grad_norm": 13.5630521774292,
      "learning_rate": 1.8841427735517847e-05,
      "loss": 1.3638,
      "step": 200
    },
    {
      "epoch": 0.7293946024799417,
      "grad_norm": 4.662814140319824,
      "learning_rate": 1.8548858981860738e-05,
      "loss": 1.2688,
      "step": 250
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 14.282145500183105,
      "learning_rate": 1.825629022820363e-05,
      "loss": 1.3666,
      "step": 300
    },
    {
      "epoch": 1.0204230488694384,
      "grad_norm": 12.253617286682129,
      "learning_rate": 1.7963721474546522e-05,
      "loss": 1.0311,
      "step": 350
    },
    {
      "epoch": 1.1663019693654266,
      "grad_norm": 31.73344612121582,
      "learning_rate": 1.767115272088941e-05,
      "loss": 0.9896,
      "step": 400
    },
    {
      "epoch": 1.312180889861415,
      "grad_norm": 32.779144287109375,
      "learning_rate": 1.73785839672323e-05,
      "loss": 1.2554,
      "step": 450
    },
    {
      "epoch": 1.4580598103574034,
      "grad_norm": 7.208659648895264,
      "learning_rate": 1.708601521357519e-05,
      "loss": 1.1292,
      "step": 500
    },
    {
      "epoch": 1.6039387308533917,
      "grad_norm": 12.13223934173584,
      "learning_rate": 1.679344645991808e-05,
      "loss": 0.8222,
      "step": 550
    },
    {
      "epoch": 1.74981765134938,
      "grad_norm": 5.1472368240356445,
      "learning_rate": 1.6500877706260974e-05,
      "loss": 1.1543,
      "step": 600
    },
    {
      "epoch": 1.8956965718453684,
      "grad_norm": 8.055643081665039,
      "learning_rate": 1.6208308952603865e-05,
      "loss": 0.9238,
      "step": 650
    },
    {
      "epoch": 2.0408460977388767,
      "grad_norm": 16.592517852783203,
      "learning_rate": 1.5915740198946755e-05,
      "loss": 0.8777,
      "step": 700
    },
    {
      "epoch": 2.186725018234865,
      "grad_norm": 7.773191928863525,
      "learning_rate": 1.5623171445289646e-05,
      "loss": 0.9829,
      "step": 750
    },
    {
      "epoch": 2.3326039387308533,
      "grad_norm": 20.80533790588379,
      "learning_rate": 1.5330602691632536e-05,
      "loss": 0.8035,
      "step": 800
    },
    {
      "epoch": 2.4784828592268418,
      "grad_norm": 6.3439788818359375,
      "learning_rate": 1.5038033937975425e-05,
      "loss": 1.0038,
      "step": 850
    },
    {
      "epoch": 2.62436177972283,
      "grad_norm": 8.706280708312988,
      "learning_rate": 1.4745465184318315e-05,
      "loss": 1.1297,
      "step": 900
    },
    {
      "epoch": 2.7702407002188183,
      "grad_norm": 7.851698875427246,
      "learning_rate": 1.4452896430661208e-05,
      "loss": 0.8789,
      "step": 950
    },
    {
      "epoch": 2.916119620714807,
      "grad_norm": 17.026033401489258,
      "learning_rate": 1.4160327677004098e-05,
      "loss": 0.8696,
      "step": 1000
    },
    {
      "epoch": 3.061269146608315,
      "grad_norm": 0.10129941254854202,
      "learning_rate": 1.3867758923346989e-05,
      "loss": 0.6144,
      "step": 1050
    },
    {
      "epoch": 3.2071480671043036,
      "grad_norm": 11.059666633605957,
      "learning_rate": 1.3575190169689877e-05,
      "loss": 0.9357,
      "step": 1100
    },
    {
      "epoch": 3.3530269876002916,
      "grad_norm": 0.031915463507175446,
      "learning_rate": 1.3282621416032768e-05,
      "loss": 0.7611,
      "step": 1150
    },
    {
      "epoch": 3.49890590809628,
      "grad_norm": 0.043642617762088776,
      "learning_rate": 1.2990052662375658e-05,
      "loss": 0.6004,
      "step": 1200
    },
    {
      "epoch": 3.644784828592268,
      "grad_norm": 33.2487678527832,
      "learning_rate": 1.269748390871855e-05,
      "loss": 0.8973,
      "step": 1250
    },
    {
      "epoch": 3.7906637490882567,
      "grad_norm": 0.17498868703842163,
      "learning_rate": 1.2404915155061441e-05,
      "loss": 0.7355,
      "step": 1300
    },
    {
      "epoch": 3.936542669584245,
      "grad_norm": 0.2179119735956192,
      "learning_rate": 1.2112346401404331e-05,
      "loss": 0.9272,
      "step": 1350
    },
    {
      "epoch": 4.081692195477753,
      "grad_norm": 8.633244514465332,
      "learning_rate": 1.1819777647747222e-05,
      "loss": 0.8513,
      "step": 1400
    },
    {
      "epoch": 4.227571115973742,
      "grad_norm": 9.492315292358398,
      "learning_rate": 1.1527208894090112e-05,
      "loss": 0.7715,
      "step": 1450
    },
    {
      "epoch": 4.37345003646973,
      "grad_norm": 0.08183056861162186,
      "learning_rate": 1.1234640140433003e-05,
      "loss": 0.6946,
      "step": 1500
    },
    {
      "epoch": 4.519328956965719,
      "grad_norm": 0.03581872954964638,
      "learning_rate": 1.0942071386775895e-05,
      "loss": 0.6175,
      "step": 1550
    },
    {
      "epoch": 4.6652078774617065,
      "grad_norm": 0.012637225911021233,
      "learning_rate": 1.0649502633118785e-05,
      "loss": 0.8041,
      "step": 1600
    },
    {
      "epoch": 4.811086797957695,
      "grad_norm": 0.2521982491016388,
      "learning_rate": 1.0356933879461674e-05,
      "loss": 0.6653,
      "step": 1650
    },
    {
      "epoch": 4.9569657184536835,
      "grad_norm": 12.266249656677246,
      "learning_rate": 1.0064365125804565e-05,
      "loss": 0.6629,
      "step": 1700
    },
    {
      "epoch": 5.102115244347192,
      "grad_norm": 10.951870918273926,
      "learning_rate": 9.771796372147455e-06,
      "loss": 0.7129,
      "step": 1750
    },
    {
      "epoch": 5.24799416484318,
      "grad_norm": 0.03288504481315613,
      "learning_rate": 9.479227618490347e-06,
      "loss": 0.6435,
      "step": 1800
    },
    {
      "epoch": 5.393873085339169,
      "grad_norm": 0.020081814378499985,
      "learning_rate": 9.186658864833236e-06,
      "loss": 0.3463,
      "step": 1850
    },
    {
      "epoch": 5.539752005835156,
      "grad_norm": 0.021039757877588272,
      "learning_rate": 8.894090111176126e-06,
      "loss": 0.598,
      "step": 1900
    },
    {
      "epoch": 5.685630926331145,
      "grad_norm": 1.022928237915039,
      "learning_rate": 8.601521357519019e-06,
      "loss": 0.729,
      "step": 1950
    },
    {
      "epoch": 5.831509846827133,
      "grad_norm": 0.03250598907470703,
      "learning_rate": 8.308952603861909e-06,
      "loss": 0.6808,
      "step": 2000
    },
    {
      "epoch": 5.977388767323122,
      "grad_norm": 15.518658638000488,
      "learning_rate": 8.016383850204798e-06,
      "loss": 0.6075,
      "step": 2050
    },
    {
      "epoch": 6.12253829321663,
      "grad_norm": 13.40859603881836,
      "learning_rate": 7.723815096547688e-06,
      "loss": 0.4172,
      "step": 2100
    },
    {
      "epoch": 6.268417213712619,
      "grad_norm": 12.036652565002441,
      "learning_rate": 7.4312463428905805e-06,
      "loss": 0.6411,
      "step": 2150
    },
    {
      "epoch": 6.414296134208607,
      "grad_norm": 0.06260468065738678,
      "learning_rate": 7.13867758923347e-06,
      "loss": 0.3726,
      "step": 2200
    },
    {
      "epoch": 6.560175054704596,
      "grad_norm": 0.014999770559370518,
      "learning_rate": 6.8461088355763606e-06,
      "loss": 0.4874,
      "step": 2250
    },
    {
      "epoch": 6.706053975200583,
      "grad_norm": 17.989084243774414,
      "learning_rate": 6.553540081919252e-06,
      "loss": 0.8278,
      "step": 2300
    },
    {
      "epoch": 6.851932895696572,
      "grad_norm": 28.21773910522461,
      "learning_rate": 6.260971328262142e-06,
      "loss": 0.5701,
      "step": 2350
    },
    {
      "epoch": 6.99781181619256,
      "grad_norm": 17.315893173217773,
      "learning_rate": 5.968402574605032e-06,
      "loss": 0.3895,
      "step": 2400
    },
    {
      "epoch": 7.1429613420860685,
      "grad_norm": 0.008620099164545536,
      "learning_rate": 5.675833820947923e-06,
      "loss": 0.5398,
      "step": 2450
    },
    {
      "epoch": 7.288840262582057,
      "grad_norm": 0.13962619006633759,
      "learning_rate": 5.383265067290814e-06,
      "loss": 0.4817,
      "step": 2500
    },
    {
      "epoch": 7.4347191830780455,
      "grad_norm": 0.05866195634007454,
      "learning_rate": 5.090696313633704e-06,
      "loss": 0.4621,
      "step": 2550
    },
    {
      "epoch": 7.580598103574033,
      "grad_norm": 12.74638843536377,
      "learning_rate": 4.798127559976595e-06,
      "loss": 0.5124,
      "step": 2600
    },
    {
      "epoch": 7.726477024070022,
      "grad_norm": 0.7159371376037598,
      "learning_rate": 4.505558806319485e-06,
      "loss": 0.463,
      "step": 2650
    },
    {
      "epoch": 7.87235594456601,
      "grad_norm": 19.011859893798828,
      "learning_rate": 4.2129900526623764e-06,
      "loss": 0.478,
      "step": 2700
    },
    {
      "epoch": 8.017505470459518,
      "grad_norm": 14.59363842010498,
      "learning_rate": 3.920421299005266e-06,
      "loss": 0.3925,
      "step": 2750
    },
    {
      "epoch": 8.163384390955507,
      "grad_norm": 10.253318786621094,
      "learning_rate": 3.6278525453481574e-06,
      "loss": 0.463,
      "step": 2800
    },
    {
      "epoch": 8.309263311451495,
      "grad_norm": 0.06687083840370178,
      "learning_rate": 3.3352837916910474e-06,
      "loss": 0.3205,
      "step": 2850
    },
    {
      "epoch": 8.455142231947484,
      "grad_norm": 0.02347271703183651,
      "learning_rate": 3.0427150380339383e-06,
      "loss": 0.3363,
      "step": 2900
    },
    {
      "epoch": 8.601021152443472,
      "grad_norm": 0.009781659580767155,
      "learning_rate": 2.7501462843768288e-06,
      "loss": 0.4923,
      "step": 2950
    },
    {
      "epoch": 8.74690007293946,
      "grad_norm": 0.016025865450501442,
      "learning_rate": 2.4575775307197192e-06,
      "loss": 0.5972,
      "step": 3000
    },
    {
      "epoch": 8.89277899343545,
      "grad_norm": 25.914817810058594,
      "learning_rate": 2.16500877706261e-06,
      "loss": 0.391,
      "step": 3050
    },
    {
      "epoch": 9.037928519328958,
      "grad_norm": 12.204154014587402,
      "learning_rate": 1.8724400234055004e-06,
      "loss": 0.3815,
      "step": 3100
    },
    {
      "epoch": 9.183807439824946,
      "grad_norm": 0.0346820242702961,
      "learning_rate": 1.5798712697483908e-06,
      "loss": 0.2899,
      "step": 3150
    },
    {
      "epoch": 9.329686360320933,
      "grad_norm": 16.363645553588867,
      "learning_rate": 1.2873025160912817e-06,
      "loss": 0.3652,
      "step": 3200
    },
    {
      "epoch": 9.475565280816921,
      "grad_norm": 0.05692350119352341,
      "learning_rate": 9.947337624341722e-07,
      "loss": 0.3995,
      "step": 3250
    },
    {
      "epoch": 9.62144420131291,
      "grad_norm": 7.845355033874512,
      "learning_rate": 7.021650087770627e-07,
      "loss": 0.4799,
      "step": 3300
    },
    {
      "epoch": 9.767323121808898,
      "grad_norm": 12.933267593383789,
      "learning_rate": 4.0959625511995324e-07,
      "loss": 0.3728,
      "step": 3350
    },
    {
      "epoch": 9.913202042304887,
      "grad_norm": 0.011430857703089714,
      "learning_rate": 1.1702750146284377e-07,
      "loss": 0.4598,
      "step": 3400
    }
  ],
  "logging_steps": 50,
  "max_steps": 3420,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.951846495047219e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
